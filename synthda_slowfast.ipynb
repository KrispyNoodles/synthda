{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NVIDIA/synthda/blob/main/synthda_slowfast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn_uFXQlNIXs"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnZUtY_pM-Jz",
        "outputId": "18d08635-d380-4978-9978-0c662cae4493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/MyDrive; to attempt to forcibly remount, call drive.mount(\"/content/MyDrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPwjpfzCNXWx"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2fS_IoZNwxj",
        "outputId": "0ac2ce32-3cfa-4a9e-81aa-76c92925e043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.11.0+cu113 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.11.0+cu113\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (0.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath) (4.14.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath) (3.2.0)\n",
            "Requirement already satisfied: pytorchvideo==0.1.5 in /usr/local/lib/python3.11/dist-packages (0.1.5)\n",
            "Requirement already satisfied: fvcore==0.1.5.post20221221 in /usr/local/lib/python3.11/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from pytorchvideo==0.1.5) (14.4.0)\n",
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.11/dist-packages (from pytorchvideo==0.1.5) (0.9.0)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (from pytorchvideo==0.1.5) (0.1.10)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pytorchvideo==0.1.5) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore==0.1.5.post20221221) (2.0.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore==0.1.5.post20221221) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore==0.1.5.post20221221) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore==0.1.5.post20221221) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore==0.1.5.post20221221) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore==0.1.5.post20221221) (11.2.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore==0.1.5.post20221221) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath->pytorchvideo==0.1.5) (4.14.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath->pytorchvideo==0.1.5) (3.2.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (59.5.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: setuptools==59.5.0 in /usr/local/lib/python3.11/dist-packages (59.5.0)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio===0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install 'iopath'\n",
        "\n",
        "!pip install pytorchvideo==0.1.5 fvcore==0.1.5.post20221221\n",
        "!pip install tensorboard\n",
        "!pip install setuptools==59.5.0\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPBr84WNWW2"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-MZua-5Nrwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fc0221-5f9d-4153-ffe0-735023eb0da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import gc\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch\n",
        "import torchvision\n",
        "import pytorchvideo\n",
        "import torchinfo\n",
        "\n",
        "from pytorchvideo.models.hub import c2d_r50, i3d_r50, slow_r50, slowfast_r50\n",
        "from pytorchvideo.models.hub import x3d_m\n",
        "from torchvision.transforms.functional import normalize, crop, hflip\n",
        "from torchvision.transforms._functional_video import center_crop\n",
        "#from pytorchvideo.transforms.functional import short_side_scale"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pytorchvideo\n",
        "#from pytorchvideo.transforms.functional import short_side_scale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3VxgxLtrmGd",
        "outputId": "5c74f72c-8354-4715-a9b6-77a83e4610d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorchvideo in /usr/local/lib/python3.11/dist-packages (0.1.5)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (0.1.5.post20221221)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (14.4.0)\n",
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (0.1.10)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (2.0.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (11.2.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore->pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath->pytorchvideo) (4.14.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath->pytorchvideo) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def short_side_scale(video: torch.Tensor, size: int):\n",
        "    \"\"\"\n",
        "    Resize so the shorter spatial side == `size`, keeping aspect ratio.\n",
        "    video: (T, C, H, W) or (C, T, H, W) tensor\n",
        "    \"\"\"\n",
        "    from torchvision.transforms.functional import resize\n",
        "    t, c, h, w = video.shape if video.ndim == 4 else (None,)*4\n",
        "    short, long = (h, w) if h < w else (w, h)\n",
        "    new_short, new_long = size, int(size * long / short)\n",
        "    # output: (T,C,H,W)\n",
        "    return resize(video, [new_short, new_long])"
      ],
      "metadata": {
        "id": "C0vn-PJCr7FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJMNKZ1PoOSF",
        "outputId": "8dcf1d70-272e-48dd-8af6-8c9e0db88bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/dist-packages (0.1.10)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: pytorchvideo in /usr/local/lib/python3.11/dist-packages (0.1.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (59.5.0)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath) (4.14.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath) (3.2.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (14.4.0)\n",
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pytorchvideo) (3.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install iopath fvcore pytorchvideo tensorboard setuptools torchinfo opencv-python seaborn numpy Pillow scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RfaH8aLOO2c"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CATr1MZFOx8r"
      },
      "outputs": [],
      "source": [
        "# function to create directories\n",
        "def create_dir(target_dir):\n",
        "    if not os.path.exists(target_dir):\n",
        "        try:\n",
        "            os.makedirs(target_dir)\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_HQQUkGOQ4n"
      },
      "outputs": [],
      "source": [
        "def write_action(action_filepath,action_name,action_id,action_type,tabsize=2):\n",
        "    action_name_str = '\\tname: \"{}\"'.format(action_name)\n",
        "    action_id_str = '\\tlabel_id: {}'.format(action_id)\n",
        "    action_type_str = '\\tlabel_type: {}'.format(action_type)\n",
        "\n",
        "    with open(action_filepath, 'a') as action_file:\n",
        "        action_file.write('label {\\n')\n",
        "        action_file.write(action_name_str.expandtabs(tabsize))\n",
        "        action_file.write('\\n')\n",
        "        action_file.write(action_id_str.expandtabs(tabsize))\n",
        "        action_file.write('\\n')\n",
        "        action_file.write(action_type_str.expandtabs(tabsize))\n",
        "        action_file.write('\\n')\n",
        "        action_file.write('}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeGnbia7XZPi"
      },
      "outputs": [],
      "source": [
        "# function to get videoinfo\n",
        "def get_videoinfo(videofile):\n",
        "\n",
        "    stream = cv2.VideoCapture(videofile)\n",
        "    assert stream.isOpened(), 'Cannot capture source'\n",
        "\n",
        "    datalen = int(stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = stream.get(cv2.CAP_PROP_FPS)\n",
        "    frameSize = (int(stream.get(cv2.CAP_PROP_FRAME_WIDTH)), int(stream.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "    fourcc = int(stream.get(cv2.CAP_PROP_FOURCC))\n",
        "    videoinfo = {'no_images': datalen, 'fps': fps, 'frameSize': frameSize, 'fourcc': decode_fourcc(fourcc)}\n",
        "\n",
        "    stream.release()\n",
        "\n",
        "    return videoinfo\n",
        "\n",
        "# function to decode fourcc\n",
        "def decode_fourcc(cc):\n",
        "    return \"\".join([chr((int(cc) >> 8 * i) & 0xFF) for i in range(4)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJkT5-byb9YI"
      },
      "outputs": [],
      "source": [
        "# function to split df into train and test sets\n",
        "def split(split_data,split_target,split_size,split_label_1,split_label_2):\n",
        "\n",
        "    # get the locations\n",
        "    X = split_data.drop(columns=[split_target])\n",
        "    y = split_data[split_target]\n",
        "\n",
        "    # split the dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_size, random_state=297,stratify=y)\n",
        "\n",
        "    # determine fold\n",
        "    X_train[split_target] = y_train\n",
        "    X_train['fold'] = split_label_1\n",
        "\n",
        "    X_test[split_target] = y_test\n",
        "    X_test['fold'] = split_label_2\n",
        "\n",
        "    # concat\n",
        "    split_df = pd.concat([X_train,X_test])\n",
        "\n",
        "    return split_df, X_train, X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOMx39qLeB9E"
      },
      "outputs": [],
      "source": [
        "# convert video into images\n",
        "def vid_to_img(videofile,img_dest_dir):\n",
        "\n",
        "  # create img_dest_dir\n",
        "  os.makedirs(img_dest_dir,exist_ok=True)\n",
        "\n",
        "  # read video and save images\n",
        "  img_paths = []\n",
        "  stream = cv2.VideoCapture(videofile)\n",
        "  assert stream.isOpened(), 'Cannot capture source'\n",
        "\n",
        "  datalen = int(stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  for i in tqdm(range(datalen),total=datalen):\n",
        "    (grabbed, frame) = stream.read()\n",
        "    img_path = os.path.join(img_dest_dir,'{}.jpg'.format(i))\n",
        "    cv2.imwrite(img_path,frame)\n",
        "    img_paths.append(img_path)\n",
        "\n",
        "  stream.release()\n",
        "\n",
        "  return img_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoKD4hmEdD3W"
      },
      "outputs": [],
      "source": [
        "def create_frames_dir(in_df_video_info,in_frames_dir):\n",
        "\n",
        "    out_df_frame_info = pd.DataFrame(columns=['vid_id','frame_id','training_frame_path'])\n",
        "\n",
        "    # obtain video_ids\n",
        "    video_ids = list(in_df_video_info['vid_id'])\n",
        "\n",
        "    # copy images into frames_dir\n",
        "    for i, video_id in enumerate(video_ids):\n",
        "        df_video = in_df_video_info.loc[in_df_video_info['vid_id']==video_id]\n",
        "\n",
        "        if df_video.empty:\n",
        "            print(f\"Warning: No video found with vid_id {video_id}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        assert len(df_video) == 1\n",
        "\n",
        "        print('Extracting images for video {} of {}'.format(i+1,len(video_ids)))\n",
        "        img_dest_dir = os.path.join(in_frames_dir,str(video_id))\n",
        "        os.makedirs(img_dest_dir,exist_ok=True)\n",
        "\n",
        "        # obtain video_images\n",
        "        image_paths = vid_to_img(df_video['video_path'].iloc[0],img_dest_dir)\n",
        "\n",
        "        for image_path in image_paths:\n",
        "\n",
        "            # rename image\n",
        "            image_name = os.path.basename(image_path)\n",
        "            frame_id = int(image_name.split('.')[0])\n",
        "\n",
        "            # store info\n",
        "            df_dict = pd.DataFrame.from_dict({'vid_id':[video_id],\n",
        "                                              'frame_id':[frame_id],\n",
        "                                              'training_frame_path':[image_path]})\n",
        "            out_df_frame_info = pd.concat([out_df_frame_info,df_dict],ignore_index=True)\n",
        "\n",
        "    return out_df_frame_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqA2micBV29B"
      },
      "outputs": [],
      "source": [
        "def create_frame_lists_csv(in_df):\n",
        "\n",
        "    out_df = pd.DataFrame(columns=['vid_id','frame_id','rel_path'])\n",
        "\n",
        "    for i, row_i in tqdm(in_df.iterrows(),total=len(in_df)):\n",
        "\n",
        "        # obtain video info\n",
        "        vid_id = row_i['vid_id']\n",
        "        video_path = row_i['video_path']\n",
        "\n",
        "        # obtain images\n",
        "        dst_folder = os.path.join(FRAMES_DIR,str(vid_id))\n",
        "        video_images = sorted(glob.glob(str(os.path.join(dst_folder,'*.jpg'))))\n",
        "\n",
        "        for image in video_images:\n",
        "            image_name = os.path.basename(image)\n",
        "            frame_id = int(image_name.split('.')[0])\n",
        "            rel_path = str(os.path.join(str(vid_id),image_name))\n",
        "\n",
        "            # store info\n",
        "            df_dict = pd.DataFrame.from_dict({'vid_id':[vid_id],\n",
        "                                              'frame_id':[frame_id],\n",
        "                                              'rel_path':[rel_path]})\n",
        "            out_df = pd.concat([out_df,df_dict],ignore_index=True)\n",
        "\n",
        "    return out_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noeP5fZ_aFhw"
      },
      "outputs": [],
      "source": [
        "def create_annotations_csv(in_df):\n",
        "\n",
        "    out_df = pd.DataFrame(columns=['vid_id', 'frame_id',\n",
        "                                   'frame_timestamp',\n",
        "                                   'action_label'])\n",
        "\n",
        "    for i, row_i in tqdm(in_df.iterrows(),total=len(in_df)):\n",
        "\n",
        "        # obtain necessary video info\n",
        "        vid_id = row_i['vid_id']\n",
        "        action_id = row_i['action_id']\n",
        "        video_fps = row_i['fps']\n",
        "\n",
        "        # obtain images\n",
        "        dst_folder = os.path.join(FRAMES_DIR,str(vid_id))\n",
        "        video_images = sorted(glob.glob(str(os.path.join(dst_folder,'*.jpg'))))\n",
        "\n",
        "        for image in video_images:\n",
        "\n",
        "            # obtain variables\n",
        "            image_name = os.path.basename(image)\n",
        "            frame_id = int(image_name.split('.')[0].split('_')[-1])\n",
        "            frame_timestamp = frame_id / video_fps\n",
        "\n",
        "            # store\n",
        "            df_dict = pd.DataFrame.from_dict({'vid_id':[vid_id],\n",
        "                                              'frame_id':[frame_id],\n",
        "                                              'frame_timestamp':[frame_timestamp],\n",
        "                                              'action_label':[action_id]})\n",
        "\n",
        "            out_df = pd.concat([out_df,df_dict],ignore_index=True)\n",
        "\n",
        "    return out_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9z_MIAxgaLP"
      },
      "outputs": [],
      "source": [
        "def clip_sampler_random(in_last_clip_end_time,in_is_last_clip,in_frame_ids):\n",
        "    \"\"\"\n",
        "    Randomly samples clip of size CLIP_DURATION (in terms of number of frames) from video frames.\n",
        "    Args:\n",
        "        in_last_clip_end_time (int): the last frame id of last clip that was sampled\n",
        "        in_is_last_clip (int): current clip count for random sampling\n",
        "        in_frame_ids (list): list of all frame_ids for video\n",
        "    Returns:\n",
        "        out_clip_start_frame (int): starting frame id of the sampled clip\n",
        "        out_clip_end_frame (int): ending frame id of the sampled clip\n",
        "        out_is_last_clip: indicator to control when clip sampling ends\n",
        "    \"\"\"\n",
        "\n",
        "    max_possible_clip_start = max(len(in_frame_ids) - CLIP_DURATION, 0)\n",
        "\n",
        "    out_clip_start = random.randint(0, max_possible_clip_start)\n",
        "    out_clip_end = out_clip_start + CLIP_DURATION\n",
        "\n",
        "    if in_is_last_clip == None:\n",
        "        out_is_last_clip = 1\n",
        "    elif isinstance(in_is_last_clip, int) and in_is_last_clip <= 3:\n",
        "        out_is_last_clip = in_is_last_clip + 1\n",
        "    else:\n",
        "        out_is_last_clip = 'Yes'\n",
        "\n",
        "    return out_clip_start, out_clip_end, out_is_last_clip\n",
        "\n",
        "def clip_sampler_uniform(in_last_clip_end_time,in_is_last_clip,in_frame_ids):\n",
        "\n",
        "    if in_is_last_clip==None:\n",
        "        out_clip_start = 0\n",
        "        out_clip_end = CLIP_DURATION\n",
        "    else:\n",
        "        out_clip_start = in_last_clip_end_time\n",
        "        out_clip_end = out_clip_start + CLIP_DURATION\n",
        "\n",
        "    if out_clip_end + CLIP_DURATION >= len(in_frame_ids):\n",
        "        out_is_last_clip = 'Yes'\n",
        "    else:\n",
        "        out_is_last_clip = 'No'\n",
        "\n",
        "    return out_clip_start, out_clip_end, out_is_last_clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dU2b01rSxLsf"
      },
      "outputs": [],
      "source": [
        "def RandomShortSideScale(in_video_frames,in_min_size,in_max_size):\n",
        "    size = torch.randint(in_min_size, in_max_size + 1, (1,)).item()\n",
        "    return short_side_scale(in_video_frames, size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuKY7a4DsCTe"
      },
      "outputs": [],
      "source": [
        "def read_label_map(in_label_map_file):\n",
        "    \"\"\"\n",
        "    Read label map and class ids.\n",
        "    Args:\n",
        "    in_label_map_file (str): Path to a .pbtxt containing class id's and class names\n",
        "    Returns:\n",
        "    out_label_map (dict): A dictionary mapping class id to the associated class names.\n",
        "    out_class_ids (set): A set of integer unique class id's\n",
        "    \"\"\"\n",
        "    out_label_map = {}\n",
        "    out_class_ids = set()\n",
        "    name = \"\"\n",
        "    class_id = \"\"\n",
        "    with open(in_label_map_file, \"r\") as f:\n",
        "        for line in f:\n",
        "            if line.startswith(\"  name:\"):\n",
        "                name = line.split('\"')[1]\n",
        "            elif line.startswith(\"  id:\") or line.startswith(\"  label_id:\"):\n",
        "                class_id = int(line.strip().split(\" \")[-1])\n",
        "                out_label_map[class_id] = name\n",
        "                out_class_ids.add(class_id)\n",
        "    return out_label_map, out_class_ids\n",
        "\n",
        "def load_image_lists(in_frame_paths_file, in_video_path_prefix):\n",
        "    \"\"\"\n",
        "    Loading image paths from the corresponding file.\n",
        "    Args:\n",
        "    in_frame_paths_file (str): Path to a file containing relative paths\n",
        "        to all the frames in the video. Each line in the file is of the\n",
        "        form <video_name frame_id rel_path>\n",
        "    in_video_path_prefix (str): Path to be augumented to the each relative\n",
        "        frame path to get the global frame path\n",
        "    Returns:\n",
        "    out_image_paths_list: A dictionary of list containing absolute frame paths.\n",
        "        Wherein the outer dictionary is per video and inner dictionary is per frame id.\n",
        "    \"\"\"\n",
        "\n",
        "    out_image_paths = {}\n",
        "\n",
        "    with open(in_frame_paths_file, \"r\") as f:\n",
        "        for line in f:\n",
        "            row = line.split()\n",
        "            assert len(row) == 3\n",
        "\n",
        "            # obtain vid_id\n",
        "            vid_id = row[0]\n",
        "\n",
        "            # add info to dictionary\n",
        "            if vid_id not in out_image_paths:\n",
        "                out_image_paths[vid_id] = {}\n",
        "\n",
        "            # obtain frame_id and absolute frame paths\n",
        "            frame_id = int(row[1])\n",
        "            frame_path = os.path.join(in_video_path_prefix, row[2])\n",
        "\n",
        "            # store absolute frame paths\n",
        "            out_image_paths[vid_id][frame_id] = frame_path\n",
        "\n",
        "    # sort frame_paths by frame_id\n",
        "    out_image_paths_list = {}\n",
        "    for vid_id in out_image_paths:\n",
        "        out_image_paths_list[vid_id] = {}\n",
        "        sorted_frame_ids = sorted(out_image_paths[vid_id])\n",
        "        for frame_id in sorted_frame_ids:\n",
        "            out_image_paths_list[vid_id][frame_id] = out_image_paths[vid_id][frame_id]\n",
        "\n",
        "    return out_image_paths_list\n",
        "\n",
        "def load_and_parse_labels_csv(in_frame_labels_file,in_allowed_class_ids=None):\n",
        "    \"\"\"\n",
        "    Parses Kinetics per frame labels .csv file.\n",
        "    Args:\n",
        "    in_frame_labels_file (str): Path to the file containing labels per key frame. The file format is given by\n",
        "        <video_name, frame_id, frame_timestamp, action_label>\n",
        "    in_allowed_class_ids (set): A set of integer unique class id's that are allowed in the dataset.\n",
        "        If none, all class id's are allowed in the bbox labels.\n",
        "    Returns:\n",
        "    out_labels_dict: A dictionary of dictionary containing labels per each keyframe in each video.\n",
        "        Here, the label for each keyframe is again a dict of the form,\n",
        "        {\n",
        "            'frame_timestamp': timestamp of keyframe\n",
        "            'labels': a list of action labels for the bounding box\n",
        "        }\n",
        "    \"\"\"\n",
        "    out_labels_dict = {}\n",
        "    with open(in_frame_labels_file, \"r\") as f:\n",
        "        for line in f:\n",
        "            row = line.strip().split(\",\")\n",
        "            assert len(row) == 4\n",
        "\n",
        "            # obtain info\n",
        "            vid_id = row[0]\n",
        "            frame_id = int(row[1])\n",
        "            frame_timestamp = float(row[2])\n",
        "            label = -1 if row[3] == \"\" else int(row[3])\n",
        "\n",
        "            # Continue if the current label is not in allowed labels\n",
        "            if (in_allowed_class_ids is not None) and (label not in in_allowed_class_ids):\n",
        "                continue\n",
        "\n",
        "            # add info to dictionaries\n",
        "            if vid_id not in out_labels_dict:\n",
        "                out_labels_dict[vid_id] = {}\n",
        "            if frame_id not in out_labels_dict[vid_id]:\n",
        "                out_labels_dict[vid_id][frame_id] = {}\n",
        "\n",
        "            out_labels_dict[vid_id][frame_id][\"frame_timestamp\"] = frame_timestamp\n",
        "            out_labels_dict[vid_id][frame_id][\"labels\"] = label\n",
        "\n",
        "    return out_labels_dict\n",
        "\n",
        "def read_kinetics_data_from_csv(in_frame_paths_file,in_frame_labels_file,in_video_path_prefix,in_label_map_file=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        in_frame_paths_file (str): Path to a file containing relative paths\n",
        "            to all the frames in the video. Each line in the file is of the form\n",
        "                <video_name frame_id rel_path>\n",
        "        in_frame_labels_file (str): Path to the file containing containing labels\n",
        "            per key frame. The file format is given by\n",
        "                <video_name, frame_id, frame_timestamp, bbox_x_1, bbox_y_1, bbox_x_2, bbox_y_2, action_label> #bbox info not used\n",
        "        in_video_path_prefix (str): Path to be augumented to the each relative frame\n",
        "            path to get the global frame path.\n",
        "        in_label_map_file (str): Path to a .pbtxt containing class id's and class names.\n",
        "            If not defined, label_map is not loaded and bbox labels are not pruned based on allowable class_id's in label_map.\n",
        "    Returns:\n",
        "        out_labeled_frame_paths: A dictionary of dictionary containing labels per each keyframe in each video.\n",
        "            Here, the label for each keyframe is again a dict of the form,\n",
        "            {\n",
        "                'frame_path': absolute location of video frame\n",
        "                'frame_timestamp': timestamp of the keyframe\n",
        "                'labels': a list of action labels for the bounding box\n",
        "            }\n",
        "    \"\"\"\n",
        "    if in_label_map_file is not None:\n",
        "        _, allowed_class_ids = read_label_map(in_label_map_file)\n",
        "    else:\n",
        "        allowed_class_ids = None\n",
        "\n",
        "    # load image paths\n",
        "    image_paths = load_image_lists(in_frame_paths_file, in_video_path_prefix)\n",
        "\n",
        "    # load frame labels\n",
        "    frame_labels = load_and_parse_labels_csv(in_frame_labels_file,in_allowed_class_ids=allowed_class_ids)\n",
        "\n",
        "    # combine all info for output\n",
        "    out_labeled_frame_paths = {}\n",
        "    for vid_id in image_paths:\n",
        "        out_labeled_frame_paths[vid_id] = {}\n",
        "        for frame_id in image_paths[vid_id]:\n",
        "\n",
        "            # get frame timestamp, labels\n",
        "            labels_info_dict = frame_labels[vid_id][frame_id]\n",
        "\n",
        "            # add frame path\n",
        "            labels_info_dict[\"frame_path\"] = image_paths[vid_id][frame_id]\n",
        "\n",
        "            # store information\n",
        "            out_labeled_frame_paths[vid_id][frame_id] = labels_info_dict\n",
        "\n",
        "    return out_labeled_frame_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqwk-EIf2Le8"
      },
      "outputs": [],
      "source": [
        "def thwc_to_cthw(in_tensor):\n",
        "    \"\"\"\n",
        "    Permute tensor from (time, height, width, channel) to (channel, time, height, width).\n",
        "    \"\"\"\n",
        "    return in_tensor.permute(3, 0, 1, 2)\n",
        "\n",
        "def load_clip_frames(in_clip_start,in_clip_end,in_frames_info_dict):\n",
        "    '''\n",
        "    Args:\n",
        "        in_clip_start_frame (int): starting frame id of clip\n",
        "        in_clip_end_frame (int): ending frame id of clip\n",
        "        in_frames_info_dict (dictionary): Here, the frame_ids serve as keys to a dict of the form,\n",
        "            {\n",
        "                'frame_path': absolute location of video frame\n",
        "                'frame_timestamp': timestamp of the keyframe\n",
        "                'labels': a list of action labels for the bounding box\n",
        "            }\n",
        "    Returns:\n",
        "        out_clip_dict (dictionary):\n",
        "            {\n",
        "                'video': a list of video frames\n",
        "                'labels': a list of action labels for each bounding box\n",
        "            }\n",
        "\n",
        "    '''\n",
        "    out_video_frames = []\n",
        "    out_labels = []\n",
        "\n",
        "    for frame_id in range(in_clip_start,in_clip_end):\n",
        "\n",
        "        # get info\n",
        "        frame_path = in_frames_info_dict[frame_id]['frame_path']\n",
        "        frame_label = in_frames_info_dict[frame_id]['labels']\n",
        "\n",
        "        # read image\n",
        "        img_bgr = cv2.imread(frame_path)\n",
        "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # store\n",
        "        out_video_frames.append(img_rgb)\n",
        "        out_labels.append([frame_label])\n",
        "\n",
        "    # check\n",
        "    assert len(out_video_frames) == CLIP_DURATION\n",
        "\n",
        "    # convert to tensor with right shape\n",
        "    out_video_frames = torch.as_tensor(np.stack(out_video_frames))\n",
        "    out_video_frames = thwc_to_cthw(out_video_frames)\n",
        "\n",
        "    out_clip_dict = {\"video\": out_video_frames,\n",
        "                    \"labels\": out_labels}\n",
        "\n",
        "    return out_clip_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYk2uSNJsp-N"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DistributedSampler\n",
        "import torch.distributed as dist\n",
        "\n",
        "class MultiProcessSampler(DistributedSampler):\n",
        "    \"\"\"\n",
        "    MultiProcessSampler handles the storage, loading, decoding and clip sampling for a video dataset.\n",
        "    It assumes each video is stored as a frame video (e.g. a folder of jpg, or png)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          dataset: An iterable dataset\n",
        "        \"\"\"\n",
        "        super().__init__(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adov88uZzO9Z"
      },
      "outputs": [],
      "source": [
        "class KineticsVideoDataset(torch.utils.data.IterableDataset):\n",
        "    \"\"\"\n",
        "    KineticsVideoDataset handles the storage, loading, decoding and clip sampling for a video dataset.\n",
        "    It assumes each video is stored as a frame video (e.g. a folder of jpg, or png)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,in_labeled_frame_paths,in_clip_sampler,in_video_sampler,in_transform_fn=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          in_labeled_frame_paths: A dictionary of dictionary containing labels per each keyframe in each video.\n",
        "            Here, the label for each keyframe is again a dict of the form,\n",
        "            {\n",
        "                'frame_path': absolute location of video frame\n",
        "                'frame_timestamp': timestamp of the keyframe\n",
        "                'labels': a list of action labels for the bounding box\n",
        "            }\n",
        "          in_clip_sampler (ClipSampler): Defines how clips should be sampled from each video.\n",
        "          in_video_sampler (Type[torch.utils.data.Sampler]): Sampler for the internal video container.\n",
        "            This defines the order videos are decoded and, if necessary, the distributed split.\n",
        "          in_transform_fn (Callable): This callable is evaluated on the dataset output before\n",
        "            the dataset is returned. It can be used for user defined preprocessing and\n",
        "            augmentations on the clips. The dataset output format is described in __next__()\n",
        "        \"\"\"\n",
        "\n",
        "        # Initialize inputs\n",
        "        self._MAX_CONSECUTIVE_FAILURES = 10\n",
        "        self._labeled_videos = in_labeled_frame_paths\n",
        "        self._clip_sampler = in_clip_sampler\n",
        "\n",
        "        # Deal with video sampler\n",
        "        # If a RandomSampler is used we need to pass in a custom random generator that ensures all PyTorch multiprocess workers have the same random seed.\n",
        "        self._video_sampler_random_generator = None\n",
        "        if in_video_sampler == torch.utils.data.RandomSampler:\n",
        "            self._video_sampler_random_generator = torch.Generator()\n",
        "            self._video_sampler = in_video_sampler(self._labeled_videos, generator=self._video_sampler_random_generator)\n",
        "        else:\n",
        "            self._video_sampler = in_video_sampler(self._labeled_videos)\n",
        "\n",
        "        self._transform = in_transform_fn\n",
        "\n",
        "        # Initialize other variables needed\n",
        "        self._video_sampler_iter = None  # Initialized on first call at self.__next__()\n",
        "\n",
        "        # Depending on the clip sampler type, we may want to sample multiple clips\n",
        "        # from one video. In that case, we keep the stored video, label and previous sampled\n",
        "        # clip time in these variables.\n",
        "        self._loaded_video = None\n",
        "        self._loaded_clip = None\n",
        "        self._last_clip_end_time = None\n",
        "        self._is_last_clip = None\n",
        "\n",
        "    @property\n",
        "    def num_videos(self):\n",
        "        \"\"\"\n",
        "        Returns: Number of videos in dataset\n",
        "        \"\"\"\n",
        "        return len(self._video_sampler)\n",
        "\n",
        "    @property\n",
        "    def num_clips(self):\n",
        "        \"\"\"\n",
        "        Returns: Number of clips in dataset\n",
        "        \"\"\"\n",
        "\n",
        "        if self._clip_sampler == clip_sampler_random:\n",
        "            return len(self._video_sampler) * 5\n",
        "        elif self._clip_sampler == clip_sampler_uniform:\n",
        "            total_clips_count = 0\n",
        "            for key, value in self._labeled_videos.items():\n",
        "                no_of_clips = len(value) // CLIP_DURATION\n",
        "                total_clips_count+= no_of_clips\n",
        "            return total_clips_count\n",
        "\n",
        "\n",
        "    def __iter__(self):\n",
        "        self._video_sampler_iter = None  # Reset video sampler\n",
        "\n",
        "        # If we're in a PyTorch DataLoader multiprocessing context, we need to use the same seed for each worker's RandomSampler generator.\n",
        "        # The workers at each __iter__ call are created from the unique value: worker_info.seed - worker_info.id, which we can use for this seed.\n",
        "        worker_info = torch.utils.data.get_worker_info() #  If worker_info is None, then this is single-process data loading\n",
        "        if self._video_sampler_random_generator is not None and worker_info is not None:\n",
        "            base_seed = worker_info.seed - worker_info.id\n",
        "            self._video_sampler_random_generator.manual_seed(base_seed)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"\n",
        "        Retrieves the next dataset based on the video sampler and clip sampling strategy.\n",
        "        Returns: A dictionary with the following format.\n",
        "        sample_dict = {\"vid_id\": id of video,\n",
        "                      \"clip_index\": clip_index (frame_id of first frame in clip),\n",
        "                      \"video\": video frames,\n",
        "                      \"labels\": labels\n",
        "                        }\n",
        "        \"\"\"\n",
        "\n",
        "        # Setup MultiProcessSampler here - after PyTorch DataLoader workers are spawned\n",
        "        if not self._video_sampler_iter:\n",
        "            self._video_sampler_iter = iter(MultiProcessSampler(self._video_sampler))\n",
        "\n",
        "        # try to load next dataset for _MAX_CONSECUTIVE_FAILURES\n",
        "        for i_try in range(self._MAX_CONSECUTIVE_FAILURES):\n",
        "\n",
        "            # Reuse previously stored video if there are still clips to be sampled from the last loaded video\n",
        "            if self._loaded_video:\n",
        "                vid_id, frame_ids, frames_info_dict = self._loaded_video\n",
        "            else:\n",
        "                video_idx = next(self._video_sampler_iter)\n",
        "                try:\n",
        "                    # get info for frames (dictionary of dictionary)\n",
        "                    # Key - frame_id (int):\n",
        "                    # Value - {'frame_timestamp': float,\n",
        "                    #'labels': action_id (int),\n",
        "                    #'frame_path': absolute frame path (str)}\n",
        "\n",
        "                    vid_id = list(self._labeled_videos.keys())[video_idx]\n",
        "                    frames_info_dict = self._labeled_videos[vid_id]\n",
        "                    frame_ids = sorted(frames_info_dict)\n",
        "\n",
        "                    self._loaded_video = (vid_id, frame_ids, frames_info_dict)\n",
        "\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            # subsample video for clips\n",
        "            clip_start,clip_end,is_last_clip = self._clip_sampler(self._last_clip_end_time,self._is_last_clip,frame_ids)\n",
        "\n",
        "            # load the next clip\n",
        "            self._loaded_clip = load_clip_frames(clip_start,clip_end,frames_info_dict)\n",
        "            self._last_clip_end_time = clip_end\n",
        "            self._is_last_clip = is_last_clip\n",
        "\n",
        "            # store necessary outputs\n",
        "            sample_dict = {\"vid_id\": vid_id,\n",
        "                           \"clip_index\": clip_start,\n",
        "                           \"video\": self._loaded_clip['video'],\n",
        "                           \"labels\": self._loaded_clip['labels']}\n",
        "\n",
        "            # carry out transformation\n",
        "            if self._transform is not None:\n",
        "                sample_dict = self._transform(sample_dict)\n",
        "\n",
        "            # Close the loaded video if last clip and reset parameters\n",
        "            if is_last_clip=='Yes':\n",
        "                self._loaded_video = None\n",
        "                self._loaded_clip = None\n",
        "                self._last_clip_end_time = None\n",
        "                self._is_last_clip = None\n",
        "\n",
        "                # Force garbage collection to release video container immediately otherwise memory can spike.\n",
        "                gc.collect()\n",
        "\n",
        "            # return sample_dict as next dataset\n",
        "            return sample_dict\n",
        "\n",
        "        # raise error after running through i_tries\n",
        "        else:\n",
        "            raise RuntimeError(f\"Failed to load video after {self._MAX_CONSECUTIVE_FAILURES} retries.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4JnHT9jjpI-"
      },
      "outputs": [],
      "source": [
        "# helper function to create Kinetics dataset\n",
        "def create_kinetics_dataset(in_frame_paths_file,in_frame_labels_file,in_video_path_prefix,in_clip_sampler,in_video_sampler,\n",
        "                       in_label_map_file=None,in_transform_fn=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        in_frame_paths_file (str): Path to a file containing relative paths\n",
        "            to all the frames in the video. Each line in the file is of the form\n",
        "                <video_name frame_id rel_path>\n",
        "        in_frame_labels_file (str): Path to the file containing containing labels\n",
        "            per key frame. The file format is given by\n",
        "                <video_name, frame_id, frame_timestamp, bbox_x_1, bbox_y_1, bbox_x_2, bbox_y_2, action_label> #bbox info not used\n",
        "        in_video_path_prefix (str): Path to be augumented to the each relative frame\n",
        "            path to get the global frame path.\n",
        "        in_clip_sampler (ClipSampler): Defines how clips should be sampled from each video.\n",
        "        in_video_sampler (Type[torch.utils.data.Sampler]): Sampler for the internal video container.\n",
        "            This defines the order videos are decoded and, if necessary, the distributed split.\n",
        "        in_label_map_file (str): Path to a .pbtxt containing class id's and class names.\n",
        "            If not defined, label_map is not loaded and bbox labels are not pruned based on allowable class_id's in label_map.\n",
        "        in_transform_fn (Optional[Callable]): This callable is evaluated on the clip output before the clip are returned.\n",
        "            It can be used for user defined preprocessing and augmentations to the clips.\n",
        "            If transform is None, the clips are returned as it is.\n",
        "    \"\"\"\n",
        "\n",
        "    labeled_frame_paths = read_kinetics_data_from_csv(in_frame_paths_file,in_frame_labels_file,in_video_path_prefix,in_label_map_file)\n",
        "\n",
        "    return KineticsVideoDataset(in_labeled_frame_paths=labeled_frame_paths,\n",
        "                           in_clip_sampler=in_clip_sampler,in_video_sampler=in_video_sampler,\n",
        "                           in_transform_fn=in_transform_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed8KqdvM_ukE"
      },
      "outputs": [],
      "source": [
        "def temporal_subsample(in_video_frames,in_labels,num_samples,temporal_dim=-3):\n",
        "    '''\n",
        "    Uniformly subsamples num_samples indices from the temporal dimension of the video.\n",
        "    When num_samples is larger than the size of temporal dimension of the video,\n",
        "    it will sample frames based on nearest neighbor interpolation\n",
        "    Args:\n",
        "        in_video_frames (torch tensor): A video tensor with a temporal dimension\n",
        "        in_labels (list): list of labels correspoinding to each video frame\n",
        "        num_samples (int): The number of equispaced samples to be selected\n",
        "        temporal_dim (int): dimension of temporal to perform temporal subsample\n",
        "    Returns:\n",
        "        Corresponding subsampled temporal outputs\n",
        "    '''\n",
        "\n",
        "    t = in_video_frames.shape[temporal_dim]\n",
        "    assert num_samples > 0 and t > 0\n",
        "\n",
        "    # Sample by nearest neighbor interpolation if num_samples > t\n",
        "    indices = torch.linspace(0,t-1,num_samples)\n",
        "    indices =  torch.clamp(indices,0,t-1).long()\n",
        "\n",
        "    # Carry out sampling\n",
        "    out_video_frames = torch.index_select(in_video_frames,temporal_dim,indices)\n",
        "    out_labels = in_labels[indices]\n",
        "\n",
        "    return out_video_frames,out_labels\n",
        "\n",
        "def Normalize(in_video_frames,in_mean,in_std):\n",
        "    out_video_frames = in_video_frames.permute(1, 0, 2, 3)  # CTHW to TCHW\n",
        "    out_video_frames = normalize(out_video_frames, mean=in_mean, std=in_std)\n",
        "    out_video_frames = out_video_frames.permute(1, 0, 2, 3)  # TCHW to CTHW\n",
        "\n",
        "    return out_video_frames\n",
        "\n",
        "\n",
        "def ShortSideScale(\n",
        "    x: torch.Tensor,\n",
        "    in_size: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Determines the shorter spatial dim of the video (i.e. width or height) and scales\n",
        "    it to the given size. To maintain aspect ratio, the longer side is then scaled\n",
        "    accordingly.\n",
        "    Args:\n",
        "        x (torch.Tensor): A video tensor of shape (C, T, H, W) and type torch.float32.\n",
        "        size (int): The size the shorter side is scaled to.\n",
        "        interpolation (str): Algorithm used for upsampling,\n",
        "            options: nearest' | 'linear' | 'bilinear' | 'bicubic' | 'trilinear' | 'area'\n",
        "    Returns:\n",
        "        An x-like Tensor with scaled spatial dims.\n",
        "    \"\"\"\n",
        "    assert len(x.shape) == 4\n",
        "    assert x.dtype == torch.float32\n",
        "    c, t, h, w = x.shape\n",
        "\n",
        "    if w < h:\n",
        "        new_h = int(math.floor((float(h) / w) * size))\n",
        "        new_w = size\n",
        "    else:\n",
        "        new_h = size\n",
        "        new_w = int(math.floor((float(w) / h) * size))\n",
        "\n",
        "    return torch.nn.functional.interpolate(x, size=(new_h, new_w), mode=\"bilinear\", align_corners=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tra3s2ri8BBp"
      },
      "outputs": [],
      "source": [
        "# for data transformations\n",
        "def transform_fn(single_input):\n",
        "\n",
        "    \"\"\"\n",
        "      works on a record level\n",
        "    \"\"\"\n",
        "\n",
        "    video_index, clip_index, video, labels = single_input[\"vid_id\"], single_input[\"clip_index\"], single_input[\"video\"], single_input[\"labels\"]\n",
        "\n",
        "    # convert labels to arrays\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Sample frames together with labels\n",
        "    video, labels = temporal_subsample(video,labels,NUM_FRAMES,temporal_dim=-3)\n",
        "\n",
        "    # Normalize the video; [0, 255] --> [0, 1]\n",
        "    video = video.float()\n",
        "    video = video / 255.0\n",
        "    height, width = video.shape[2], video.shape[3]\n",
        "\n",
        "    # Normalize images by mean and std\n",
        "    video = Normalize(video, in_mean=np.array(MEAN, dtype=np.float32), in_std=np.array(STD, dtype=np.float32))\n",
        "\n",
        "\n",
        "    if MODEL == \"x3d_m\":\n",
        "\n",
        "      # Short Side Scale\n",
        "      video = ShortSideScale(video,in_size=SIDE_SIZE)\n",
        "\n",
        "      # Center Crop Video\n",
        "      video = center_crop(video, (CROP_SIZE,CROP_SIZE))\n",
        "\n",
        "\n",
        "    else:\n",
        "\n",
        "       # Random Short Side Scale\n",
        "       video = RandomShortSideScale(video,in_min_size=MIN_SIDE_SIZE,in_max_size=MAX_SIDE_SIZE)\n",
        "\n",
        "       # Random Crop\n",
        "       video = RandomCrop(video,in_crop_size=CROP_SIZE)\n",
        "\n",
        "       # Random Horizontal Flip\n",
        "       video = RandomHorizontalFlip(video,in_p=0.5)\n",
        "\n",
        "    # Incase of slowfast, generate both pathways\n",
        "    if MODEL == \"slowfast\":\n",
        "\n",
        "         fast_pathway = video\n",
        "\n",
        "         # Perform temporal sampling from the fast pathway.\n",
        "         slow_pathway = torch.index_select(video,1,torch.linspace(0, video.shape[1] - 1, video.shape[1] // SLOWFAST_ALPHA).long())\n",
        "\n",
        "         video = [slow_pathway, fast_pathway]\n",
        "\n",
        "    return video_index, clip_index, video, torch.from_numpy(np.array(labels)).type(torch.LongTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvv5HkgCiaCt"
      },
      "outputs": [],
      "source": [
        "# collate function\n",
        "def collate_fn(batch):\n",
        "\n",
        "    if MODEL in [\"c2d\",\"i3d\",\"slow\"]:\n",
        "\n",
        "        video_names_merged, clip_indexes_merged, videos_merged, labels_merged = [], [], [], []\n",
        "\n",
        "        for clip_i, clip in enumerate(batch):\n",
        "\n",
        "            video, labels = clip\n",
        "            video_names_merged.append(clip_i)  # Using clip index as a placeholder for video name\n",
        "            videos_merged.append(video)  # Video tensor\n",
        "            labels_merged.append(labels)  # Label tensor\n",
        "            clip_indexes_merged.append(clip_i)  # Clip index\n",
        "\n",
        "        videos_merged = torch.stack(videos_merged)\n",
        "        labels_merged = torch.vstack(labels_merged)\n",
        "\n",
        "    elif MODEL == \"slowfast\":\n",
        "\n",
        "        video_names_merged, clip_indexes_merged, slow_merged, fast_merged, labels_merged = [], [], [], [], []\n",
        "\n",
        "        for clip_i, clip in enumerate(batch):\n",
        "\n",
        "            name, clip_index, video, labels = clip\n",
        "\n",
        "            video_names_merged.append(name)\n",
        "            slow_merged.append(video[0])\n",
        "            fast_merged.append(video[1])\n",
        "            labels_merged.append(labels)\n",
        "            clip_indexes_merged.append(clip_index)\n",
        "\n",
        "        slow_merged = torch.stack(slow_merged)\n",
        "        fast_merged = torch.stack(fast_merged)\n",
        "        videos_merged = [slow_merged, fast_merged]\n",
        "        labels_merged = torch.vstack(labels_merged)\n",
        "\n",
        "    return video_names_merged, clip_indexes_merged, videos_merged, labels_merged"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# added collate function for tuples for synthda\n",
        "\"\"\"\n",
        "def dict_collate_fn(batch):\n",
        "\n",
        "    Converts a list of tuples from Dataset.__getitem__()\n",
        "    into a single dictionary batch for the training loop.\n",
        "    Assumes each item in `batch` is either:\n",
        "        (video_tensor, label_int)  OR\n",
        "        (video_tensor, label_int, metadata...)\n",
        "\n",
        "    videos , labels_full = zip(*[(b[0], b[3]) for b in batch]) # ignore any extras\n",
        "\n",
        "    videos  = torch.stack(videos).float()          # [B, C, T, H, W]\n",
        "    labels  = torch.stack([l[0] for l in labels_full]).long()  # [B]\n",
        "\n",
        "    return {\"video\": videos, \"label\": labels}\n",
        "\"\"\"\n",
        "\n",
        "def dict_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Convert PyTorchVideo tuples into the dict expected by the training loop.\n",
        "    Handles single-path and SlowFast two-path inputs.\n",
        "    Returns\n",
        "    -------\n",
        "    dict(video=Tensor or list[Tensor], label=Tensor)\n",
        "    \"\"\"\n",
        "    videos, labels = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        # item is either (video, label) or (name, clip_idx, video, label)\n",
        "        video = item[0] if len(item) == 2 else item[2]\n",
        "        label = item[1] if len(item) == 2 else item[3]\n",
        "\n",
        "        # ── CASE A: video is already a tensor ───────────────────────────\n",
        "        if torch.is_tensor(video):\n",
        "            videos.append(video)\n",
        "        # ── CASE B: SlowFast – list of two tensors ─────────────────────\n",
        "        elif isinstance(video, list) and torch.is_tensor(video[0]):\n",
        "            # stack slow tensors together, fast tensors together\n",
        "            if not videos:\n",
        "                videos = [[], []]          # videos[0] = slow, videos[1] = fast\n",
        "            videos[0].append(video[0])\n",
        "            videos[1].append(video[1])\n",
        "        # ── CASE C: plain Python list/ndarray ───────────────────────────\n",
        "        else:\n",
        "            videos.append(torch.tensor(video))\n",
        "\n",
        "        # collapse per-frame labels -> single class id\n",
        "        if torch.is_tensor(label):\n",
        "            if label.ndim > 1:\n",
        "                label = torch.mode(label.squeeze(), 0).values\n",
        "            label = label.long()\n",
        "        else:\n",
        "            label = torch.tensor(label).long()\n",
        "        labels.append(label)\n",
        "\n",
        "    # -------- convert videos to batched tensor(s) ----------------------\n",
        "    if isinstance(videos, list) and len(videos) == 2 and isinstance(videos[0], list):\n",
        "        # SlowFast: stack slow path and fast path separately\n",
        "        slow_batch = torch.stack(videos[0]).float()\n",
        "        fast_batch = torch.stack(videos[1]).float()\n",
        "        videos = [slow_batch, fast_batch]\n",
        "    else:\n",
        "        videos = torch.stack(videos).float()   # single-path\n",
        "\n",
        "    labels = torch.stack(labels).long()        # [B]\n",
        "\n",
        "    return {\"video\": videos, \"label\": labels}"
      ],
      "metadata": {
        "id": "hdDh59-IldP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULWAf5YrgBEQ"
      },
      "outputs": [],
      "source": [
        "# helper function to create dataloader\n",
        "def create_dataloader(dataloader_type):\n",
        "    '''\n",
        "    dataloader_type: train, val, test\n",
        "    '''\n",
        "\n",
        "    clip_sampler_fn_mapper = {\"train\": clip_sampler_random,\n",
        "                            \"val\": clip_sampler_uniform,\n",
        "                            \"test\": clip_sampler_uniform}\n",
        "\n",
        "    kinetics_dataset = create_kinetics_dataset(in_frame_paths_file = os.path.join(FRAME_PATHS_FOLDER, \"{}.tsv\".format(dataloader_type)),\n",
        "                                     in_frame_labels_file = os.path.join(FRAME_LABELS_FOLDER, \"{}_predicted_boxes.csv\".format(dataloader_type)),\n",
        "                                     in_video_path_prefix = VIDEO_PATH_PREFIX,\n",
        "                                     in_clip_sampler = clip_sampler_fn_mapper[dataloader_type],\n",
        "                                     in_video_sampler = torch.utils.data.RandomSampler,\n",
        "                                     in_label_map_file = LABEL_MAP_FILE,\n",
        "                                     in_transform_fn = transform_fn)\n",
        "\n",
        "    #dataloader = torch.utils.data.DataLoader(kinetics_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
        "    dataloader = torch.utils.data.DataLoader(kinetics_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, collate_fn=dict_collate_fn )\n",
        "\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGy7FiawSPcq"
      },
      "outputs": [],
      "source": [
        "# helper function to freeze model weights\n",
        "def freeze_weights(in_model):\n",
        "\n",
        "    assert in_model is not None\n",
        "\n",
        "    for name, param in in_model.named_parameters():\n",
        "        if \"proj\" in name:\n",
        "            continue\n",
        "        else:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    return in_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PFOni3zQIH2"
      },
      "outputs": [],
      "source": [
        "# create model\n",
        "def create_model(in_n_classes, model_type=\"c2d\", freeze_body=False):\n",
        "\n",
        "    \"\"\"\n",
        "      in_n_classes (int): The number of classes to be predicted\n",
        "      model_type (str): The type of model to load (either slow or slowfast). Default: c2d, Others: i3d, slow, slowfast\n",
        "    \"\"\"\n",
        "\n",
        "    if model_type not in [\"c2d\",\"i3d\",\"slow\",\"slowfast\"]: raise Exception(\"Please check that type of model is either c2d, i3d, slow or slowfast\")\n",
        "\n",
        "    # input pretrained model\n",
        "    if model_type == \"c2d\":\n",
        "        video_model = c2d_r50(pretrained=True)\n",
        "        model_last_layer = 6\n",
        "    elif model_type == \"i3d\":\n",
        "        video_model = i3d_r50(pretrained=True)\n",
        "        model_last_layer = 6\n",
        "    elif model_type == \"slow\":\n",
        "        video_model = slow_r50(pretrained=True)\n",
        "        model_last_layer = 5\n",
        "    elif model_type == \"slowfast\":\n",
        "        video_model = slowfast_r50(pretrained=True)\n",
        "        model_last_layer = 6\n",
        "\n",
        "    # put model to train mode\n",
        "    video_model = video_model.train()\n",
        "\n",
        "    # freeze body layers\n",
        "    if freeze_body:\n",
        "        video_model = freeze_weights(video_model)\n",
        "\n",
        "    # Change the prediction head to the input number of classes\n",
        "    emb_dim = video_model.blocks[model_last_layer].proj.in_features\n",
        "    video_model.blocks[model_last_layer].proj = torch.nn.Linear(emb_dim, in_n_classes)\n",
        "\n",
        "    # Check if GPU is present, if not use CPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Place model on device\n",
        "    video_model = video_model.to(device)\n",
        "\n",
        "    return video_model, device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xYyC5CKWEeG"
      },
      "outputs": [],
      "source": [
        "# helper functions to write and load arguments\n",
        "def write_args(params, output_path):\n",
        "\n",
        "    with open(output_path, \"w\", encoding = \"UTF-8\") as f:\n",
        "        json.dump(params, f, indent=4)\n",
        "\n",
        "def load_args(path):\n",
        "\n",
        "    with open(path, \"r\", encoding = \"UTF-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "737lrMATYQkg"
      },
      "outputs": [],
      "source": [
        "# helper function to get predictions\n",
        "def get_predictions(in_batch, in_model, in_device):\n",
        "    \"\"\"\n",
        "    Supports both:\n",
        "      • new dict form  {\"video\": tensor|list[tensor], \"label\": tensor}\n",
        "      • old tuple form (video_idx, clip_idx, video, label)\n",
        "    Returns\n",
        "    -------\n",
        "    logits, labels\n",
        "    \"\"\"\n",
        "    # ── 1. unpack --------------------------------------------------------\n",
        "    if isinstance(in_batch, dict):                 # new collate\n",
        "        video  = in_batch[\"video\"]\n",
        "        labels = in_batch[\"label\"]\n",
        "    else:                                          # old 4-tuple\n",
        "        _, _, video, labels = in_batch\n",
        "\n",
        "    # ── 2. move video(s) to device --------------------------------------\n",
        "    if MODEL == \"slowfast\":                        # two-path model\n",
        "        # make sure we have a list [slow, fast]\n",
        "        if not isinstance(video, list):\n",
        "            raise ValueError(\"SlowFast expects a list [slow, fast]\")\n",
        "        video = [v.to(in_device, non_blocking=True) for v in video]\n",
        "    else:                                          # single-path model\n",
        "        video = video.to(in_device, non_blocking=True)\n",
        "\n",
        "    # ── 3. labels to device & squeeze -----------------------------------\n",
        "    #labels = labels.to(in_device, non_blocking=True).squeeze()\n",
        "    labels = labels.to(in_device, non_blocking=True).view(-1)\n",
        "\n",
        "    # ── 4. forward ------------------------------------------------------\n",
        "    logits = in_model(video)\n",
        "    return logits, labels\n",
        "\n",
        "# helper function to calculate model loss\n",
        "def get_loss(in_labels_pred, in_labels):\n",
        "\n",
        "    labels_OH = torch.nn.functional.one_hot(in_labels[0],num_classes=N_CLASSES).float()\n",
        "    labels_OH = torch.reshape(labels_OH,(1,-1))\n",
        "\n",
        "    out_loss = torch.nn.functional.cross_entropy(in_labels_pred,labels_OH)\n",
        "\n",
        "    return out_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUjTZIexaH-6"
      },
      "outputs": [],
      "source": [
        "# helper function for validation\n",
        "def validate(in_model, in_dataloader, in_device):\n",
        "\n",
        "    print(\"Validating model...\")\n",
        "\n",
        "    in_model.eval() # To turn off gradient and dropout\n",
        "    total_loss, total_batch = 0, 0\n",
        "    all_labels_pred, all_labels = [],[]\n",
        "    n_iter = int(np.ceil(in_dataloader.dataset.num_clips / in_dataloader.batch_size))\n",
        "\n",
        "    # We do not need to compute gradient since there's no backward pass involved in validation\n",
        "    # torch.no_grad ensures that no gradients are computed and stored\n",
        "    pbar = tqdm(total=n_iter)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in in_dataloader:\n",
        "\n",
        "            labels_pred, labels = get_predictions(batch, in_model, in_device)\n",
        "\n",
        "            loss = get_loss(labels_pred, labels)\n",
        "\n",
        "            # get prediction\n",
        "            labels_pred = torch.nn.functional.softmax(labels_pred,dim=1)\n",
        "            labels_pred = torch.argmax(labels_pred, dim=-1)\n",
        "\n",
        "            all_labels_pred.extend(labels_pred.detach().cpu().numpy().tolist()*labels.shape[0])\n",
        "            all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_batch += 1\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "        pbar.close()\n",
        "        in_model.train()\n",
        "\n",
        "        avg_loss = total_loss / total_batch\n",
        "        acc = accuracy_score(all_labels, all_labels_pred) * 100\n",
        "        f_score = f1_score(all_labels, all_labels_pred, average = \"macro\") * 100\n",
        "\n",
        "        return avg_loss, acc, f_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcWBi9Aybkkr"
      },
      "outputs": [],
      "source": [
        "# helper function to save model weights\n",
        "def save_model(save_folder, in_model, save_name):\n",
        "\n",
        "    output_path = os.path.join(save_folder, \"{}.pth\".format(save_name))\n",
        "    if hasattr(in_model, \"module\"):\n",
        "        torch.save(in_model.module.state_dict(), output_path)\n",
        "    else:\n",
        "        torch.save(in_model.state_dict(), output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTtliSZMXC5I"
      },
      "outputs": [],
      "source": [
        "def train(in_model, in_optimizer, in_dataloaders, in_model_save_dir, in_log_dir, in_device):\n",
        "\n",
        "    # for data logging\n",
        "    writer = SummaryWriter(log_dir=in_log_dir)\n",
        "    best_loss, best_acc, best_f_score = 1e3, 0, 0\n",
        "\n",
        "    print(\"num_clips:\", in_dataloaders[\"train\"].dataset.num_clips)  # Should print 1\n",
        "    print(\"batch_size:\", in_dataloaders[\"train\"].batch_size)  # Should be an integer\n",
        "\n",
        "    n_iter = int(np.ceil(in_dataloaders[\"train\"].dataset.num_clips / in_dataloaders[\"train\"].batch_size))\n",
        "    for epoch in range(N_EPOCHS):\n",
        "\n",
        "        print('Epoch {} of {}'.format(epoch+1,N_EPOCHS))\n",
        "        for i, batch in tqdm(enumerate(in_dataloaders[\"train\"]), total=n_iter):\n",
        "            #assert isinstance(batch, dict), f\"batch is {type(batch)}\"\n",
        "            # --- inside the training loop, just after you fetch `batch` -------------\n",
        "            if isinstance(batch[\"video\"], list):                     # SlowFast\n",
        "                vid_shapes = [tuple(t.shape) for t in batch[\"video\"]]\n",
        "            else:                                                    # single-path\n",
        "                vid_shapes = tuple(batch[\"video\"].shape)\n",
        "\n",
        "            print(f\"\\nBatch {i}: video {vid_shapes}, label {batch['label'].shape}\")\n",
        "\n",
        "        for i, batch in tqdm(enumerate(in_dataloaders[\"train\"]),total=n_iter):\n",
        "            in_model.train()\n",
        "            in_optimizer.zero_grad()\n",
        "\n",
        "            labels_pred, labels = get_predictions(batch, in_model, in_device)\n",
        "            loss = get_loss(labels_pred, labels)\n",
        "\n",
        "            # Backprop here\n",
        "            loss.backward()\n",
        "            in_optimizer.step()\n",
        "\n",
        "        # Calculate metrics after every epoch\n",
        "        avg_train_loss, train_acc, train_f_score = validate(in_model, in_dataloaders[\"train\"], in_device)\n",
        "        writer.add_scalar(\"Loss/train\", avg_train_loss, epoch)\n",
        "        writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
        "        writer.add_scalar(\"FScore/train\", train_f_score, epoch)\n",
        "\n",
        "        avg_val_loss, val_acc, val_f_score = validate(in_model, in_dataloaders[\"val\"], in_device)\n",
        "        writer.add_scalar(\"Loss/val\", avg_val_loss, epoch)\n",
        "        writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
        "        writer.add_scalar(\"FScore/val\", val_f_score, epoch)\n",
        "\n",
        "        if avg_val_loss <= best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            writer.add_scalar(\"Saved_models/val_loss\", best_loss, epoch)\n",
        "            save_model(in_model_save_dir, in_model, \"best_model_loss\")\n",
        "\n",
        "        if val_acc >= best_acc:\n",
        "            best_acc = val_acc\n",
        "            writer.add_scalar(\"Saved_models/val_acc\", best_acc, epoch)\n",
        "            save_model(in_model_save_dir, in_model, \"best_model_acc\")\n",
        "\n",
        "        if val_f_score >= best_f_score:\n",
        "            best_f_score = val_f_score\n",
        "            writer.add_scalar(\"Saved_models/val_f_score\", best_f_score, epoch)\n",
        "            save_model(in_model_save_dir, in_model, \"best_model_f_score\")\n",
        "\n",
        "    writer.flush()\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz8b91lKywLu"
      },
      "outputs": [],
      "source": [
        "def temporal_subsample(in_video_frames,in_labels,num_samples,temporal_dim=-3):\n",
        "    '''\n",
        "    Uniformly subsamples num_samples indices from the temporal dimension of the video.\n",
        "    When num_samples is larger than the size of temporal dimension of the video,\n",
        "    it will sample frames based on nearest neighbor interpolation\n",
        "    Args:\n",
        "        in_video_frames (torch tensor): A video tensor with a temporal dimension\n",
        "        in_labels (list): list of labels correspoinding to each video frame\n",
        "        num_samples (int): The number of equispaced samples to be selected\n",
        "        temporal_dim (int): dimension of temporal to perform temporal subsample\n",
        "    Returns:\n",
        "        Corresponding subsampled temporal outputs\n",
        "    '''\n",
        "\n",
        "    t = in_video_frames.shape[temporal_dim]\n",
        "    assert num_samples > 0 and t > 0\n",
        "\n",
        "    # Sample by nearest neighbor interpolation if num_samples > t\n",
        "    indices = torch.linspace(0,t-1,num_samples)\n",
        "    indices =  torch.clamp(indices,0,t-1).long()\n",
        "\n",
        "    # Carry out sampling\n",
        "    out_video_frames = torch.index_select(in_video_frames,temporal_dim,indices)\n",
        "    out_labels = [in_labels[i] for i in indices.tolist()]\n",
        "\n",
        "    return out_video_frames,out_labels\n",
        "\n",
        "def get_dimensions(in_tensor):\n",
        "    if not in_tensor.ndim >= 2:\n",
        "        raise TypeError(\"Tensor is not a torch image\")\n",
        "    channels = 1 if in_tensor.ndim == 2 else in_tensor.shape[-3]\n",
        "    height, width = in_tensor.shape[-2:]\n",
        "    return [channels, height, width]\n",
        "\n",
        "def Normalize(in_video_frames,in_mean,in_std):\n",
        "    out_video_frames = in_video_frames.permute(1, 0, 2, 3)  # CTHW to TCHW\n",
        "    out_video_frames = normalize(out_video_frames, mean=in_mean, std=in_std)\n",
        "    out_video_frames = out_video_frames.permute(1, 0, 2, 3)  # TCHW to CTHW\n",
        "\n",
        "    return out_video_frames\n",
        "\n",
        "def RandomShortSideScale(in_video_frames,in_min_size,in_max_size):\n",
        "    size = torch.randint(in_min_size, in_max_size + 1, (1,)).item()\n",
        "    return short_side_scale(in_video_frames, size)\n",
        "\n",
        "def RandomCrop(in_video_frames,in_crop_size):\n",
        "    size = tuple((int(in_crop_size),int(in_crop_size)))\n",
        "\n",
        "    _, h, w = get_dimensions(in_video_frames)\n",
        "    th, tw = size\n",
        "\n",
        "    if h < th or w < tw:\n",
        "        raise ValueError(f\"Required crop size {(th, tw)} is larger than input image size {(h, w)}\")\n",
        "\n",
        "    if w == tw and h == th:\n",
        "        i = 0\n",
        "        j = 0\n",
        "    else:\n",
        "        i = torch.randint(0, h - th + 1, size=(1,)).item()\n",
        "        j = torch.randint(0, w - tw + 1, size=(1,)).item()\n",
        "\n",
        "    return crop(in_video_frames, i, j, th, tw)\n",
        "\n",
        "def RandomHorizontalFlip(in_video_frames,in_p=0.5):\n",
        "    if torch.rand(1) < in_p:\n",
        "        return hflip(in_video_frames)\n",
        "\n",
        "    return in_video_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ujOXIuTl-WO"
      },
      "outputs": [],
      "source": [
        "# helper function for getting model predictions\n",
        "def obtain_model_predictions(in_model, in_dataloader, in_device):\n",
        "\n",
        "    print(\"Obtaining predictions...\")\n",
        "\n",
        "    in_model.eval() # To turn off gradient and dropout\n",
        "    out_all_labels_pred, out_all_labels = [],[]\n",
        "    n_iter = int(np.ceil(in_dataloader.dataset.num_clips / in_dataloader.batch_size))\n",
        "\n",
        "    # We do not need to compute gradient since there's no backward pass involved in validation\n",
        "    # torch.no_grad ensures that no gradients are computed and stored\n",
        "    pbar = tqdm(total=n_iter)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in in_dataloader:\n",
        "\n",
        "            labels_pred, labels = get_predictions(batch, in_model, in_device)\n",
        "\n",
        "            labels_pred = torch.nn.functional.softmax(labels_pred,dim=1)\n",
        "            labels_pred = torch.argmax(labels_pred, dim=-1)\n",
        "\n",
        "            out_all_labels_pred.extend(labels_pred.detach().cpu().numpy().tolist()*labels.shape[0])\n",
        "            out_all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "        pbar.close()\n",
        "        in_model.train()\n",
        "\n",
        "    # store relevant outputs as df\n",
        "    assert len(out_all_labels) == len(out_all_labels_pred)\n",
        "\n",
        "    out_df_model_preds = pd.DataFrame()\n",
        "    out_df_model_preds['label'] = out_all_labels\n",
        "    out_df_model_preds['prediction'] = out_all_labels_pred\n",
        "\n",
        "    out_df_model_preds['result'] = ''\n",
        "    for i, row_i in out_df_model_preds.iterrows():\n",
        "        if row_i['label'] == row_i['prediction']:\n",
        "            out_df_model_preds.at[i,'result'] = 'correct'\n",
        "        else:\n",
        "            out_df_model_preds.at[i,'result'] = 'incorrect'\n",
        "\n",
        "    return out_df_model_preds\n",
        "\n",
        "def obtain_other_model_predictions(in_model, in_dataloader, in_device, in_other_to_model_id_dict):\n",
        "\n",
        "    print(\"Obtaining predictions...\")\n",
        "\n",
        "    in_model.eval() # To turn off gradient and dropout\n",
        "    out_all_labels_pred, out_all_labels = [],[]\n",
        "    n_iter = int(np.ceil(in_dataloader.dataset.num_clips / in_dataloader.batch_size))\n",
        "\n",
        "    # We do not need to compute gradient since there's no backward pass involved in validation\n",
        "    # torch.no_grad ensures that no gradients are computed and stored\n",
        "    pbar = tqdm(total=n_iter)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in in_dataloader:\n",
        "\n",
        "            labels_pred, labels = get_predictions(batch, in_model, in_device)\n",
        "\n",
        "            labels_pred = torch.nn.functional.softmax(labels_pred,dim=1)\n",
        "            labels_pred = torch.argmax(labels_pred, dim=-1)\n",
        "\n",
        "            out_all_labels_pred.extend(labels_pred.detach().cpu().numpy().tolist()*labels.shape[0])\n",
        "            out_all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "        pbar.close()\n",
        "        in_model.train()\n",
        "\n",
        "    # store relevant outputs as df\n",
        "    assert len(out_all_labels) == len(out_all_labels_pred)\n",
        "\n",
        "    out_df_model_preds = pd.DataFrame()\n",
        "    out_df_model_preds['label'] = out_all_labels\n",
        "    out_df_model_preds['label'] = out_df_model_preds['label'].map(in_other_to_model_id_dict)\n",
        "    out_df_model_preds['prediction'] = out_all_labels_pred\n",
        "\n",
        "    out_df_model_preds['result'] = ''\n",
        "    for i, row_i in out_df_model_preds.iterrows():\n",
        "        if row_i['label'] == row_i['prediction']:\n",
        "            out_df_model_preds.at[i,'result'] = 'correct'\n",
        "        else:\n",
        "            out_df_model_preds.at[i,'result'] = 'incorrect'\n",
        "\n",
        "    return out_df_model_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwCFIiiImd4A"
      },
      "outputs": [],
      "source": [
        "def per_class_accuracy(in_df_results,in_target_class):\n",
        "\n",
        "    target_classes = sorted(list(set(in_df_results[in_target_class])))\n",
        "\n",
        "    out_class_accuracy = pd.DataFrame(columns=[in_target_class]+['total','correct','incorrect','per_correct','per_incorrect'])\n",
        "\n",
        "    for target_class in target_classes:\n",
        "        df_class = in_df_results[in_df_results[in_target_class]==target_class]\n",
        "        total = len(df_class)\n",
        "\n",
        "        df_correct = df_class[df_class['result']=='correct']\n",
        "        correct = len(df_correct)\n",
        "\n",
        "        df_incorrect = df_class[df_class['result']=='incorrect']\n",
        "        incorrect = len(df_incorrect)\n",
        "\n",
        "        assert correct + incorrect == total\n",
        "\n",
        "        per_correct = '{} %'.format(round(correct/total*100,2))\n",
        "        per_incorrect = '{} %'.format(round(incorrect/total*100,2))\n",
        "\n",
        "        # store results\n",
        "        df_dict = pd.DataFrame.from_dict({in_target_class:[target_class],\n",
        "                                          'total':[total],\n",
        "                                          'correct':[correct],\n",
        "                                          'incorrect':[incorrect],\n",
        "                                          'per_correct':[per_correct],\n",
        "                                          'per_incorrect':[per_incorrect]})\n",
        "        out_class_accuracy = pd.concat([out_class_accuracy,df_dict],ignore_index=True)\n",
        "\n",
        "    # get action\n",
        "    out_class_accuracy['action'] = out_class_accuracy[in_target_class].map(ACTION_ID_DICT)\n",
        "    out_class_accuracy = out_class_accuracy[[in_target_class,'action','total','correct','incorrect','per_correct','per_incorrect']]\n",
        "\n",
        "    # determine overall\n",
        "    total_sum = out_class_accuracy['total'].sum()\n",
        "    correct_sum = out_class_accuracy['correct'].sum()\n",
        "    incorrect_sum = out_class_accuracy['incorrect'].sum()\n",
        "\n",
        "    assert correct_sum + incorrect_sum == total_sum\n",
        "\n",
        "    per_correct_sum = '{} %'.format(round(correct_sum/total_sum*100,2))\n",
        "    per_incorrect_sum = '{} %'.format(round(incorrect_sum/total_sum*100,2))\n",
        "\n",
        "    df_dict = pd.DataFrame.from_dict({in_target_class:['Overall'],\n",
        "                                      'action':['Overall'],\n",
        "                                      'total':[total_sum],\n",
        "                                      'correct':[correct_sum],\n",
        "                                      'incorrect':[incorrect_sum],\n",
        "                                      'per_correct':[per_correct_sum],\n",
        "                                      'per_incorrect':[per_incorrect_sum]})\n",
        "    out_class_accuracy = pd.concat([out_class_accuracy,df_dict],ignore_index=True)\n",
        "\n",
        "    return out_class_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3oL4fw6nJEa"
      },
      "outputs": [],
      "source": [
        "def generate_confusion_data(in_df_match,in_label_name,in_pred_name,remove_correct=False):\n",
        "\n",
        "    # determine unique class\n",
        "    unique_classes = sorted(list(set(in_df_match[in_label_name])))\n",
        "    unique_classes += sorted(list(set(in_df_match[in_pred_name])))\n",
        "    unique_classes = sorted(list(set(unique_classes)))\n",
        "\n",
        "    # obtain data for confusion matrix\n",
        "    out_df_confusion_data = pd.DataFrame(columns=['label','prediction','number','percentage'])\n",
        "\n",
        "    for unique_label in unique_classes:\n",
        "\n",
        "        df_label = in_df_match.loc[in_df_match[in_label_name]==unique_label]\n",
        "        label_total = float(len(df_label))\n",
        "\n",
        "        if label_total != 0:\n",
        "\n",
        "            for unique_pred in unique_classes:\n",
        "\n",
        "                df_pred = df_label.loc[df_label[in_pred_name]==unique_pred]\n",
        "                pred_total = float(len(df_pred))\n",
        "\n",
        "                # remove correct predictions\n",
        "                if remove_correct:\n",
        "                    if unique_label == unique_pred:\n",
        "                        pred_total = 0\n",
        "\n",
        "                # calculate prediction percentage\n",
        "                pred_percent = round(pred_total/label_total*100,2)\n",
        "\n",
        "                # store\n",
        "                df_dict = pd.DataFrame.from_dict({'label':[unique_label],\n",
        "                                                'prediction':[unique_pred],\n",
        "                                                'number':[pred_total],\n",
        "                                                'percentage':[pred_percent]})\n",
        "\n",
        "                out_df_confusion_data = pd.concat([out_df_confusion_data,df_dict],ignore_index=True)\n",
        "\n",
        "    return out_df_confusion_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Y7H51KNY4q"
      },
      "source": [
        "# Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr9wnX9ANeNy",
        "outputId": "8fce3f24-c440-49bb-d730-696df9c70feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Videos Directory: /content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data\n",
            "Frames Directory: /content/MyDrive/MyDrive/autosynthda/action-recognition/training_data/frames\n",
            "Annotations Directory: /content/MyDrive/MyDrive/autosynthda/action-recognition/training_data/annotations\n",
            "Training Data Directory: /content/MyDrive/MyDrive/autosynthda/action-recognition/training_data\n",
            "Checkpoint Directory: /content/MyDrive/MyDrive/autosynthda/action-recognition/checkpoint\n",
            "animation_pose.py  meg_slowfast.ipynb  raw_data_random\ttraining_data\n",
            "checkpoint\t   raw_data\t       results\n",
            "Root project dir : /content/MyDrive/MyDrive/autosynthda/action-recognition\n",
            "Raw videos dir   : /content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "# path variables\n",
        "pri_dir = '/content/MyDrive/MyDrive/autosynthda/action-recognition/'\n",
        "raw_data_dir = os.path.join(pri_dir, 'raw_data')\n",
        "checkpoint_dir = os.path.join(pri_dir, 'checkpoint')\n",
        "\n",
        "training_data_dir = os.path.join(pri_dir, 'training_data')\n",
        "FRAMES_DIR = os.path.join(training_data_dir, 'frames')\n",
        "FRAME_PATHS_FOLDER = os.path.join(training_data_dir, 'frame_lists')\n",
        "FRAME_LABELS_FOLDER = os.path.join(training_data_dir, 'annotations')\n",
        "LABEL_MAP_FILE = os.path.join(FRAME_LABELS_FOLDER,\"action_list.pbtxt\")\n",
        "VIDEO_PATH_PREFIX = FRAMES_DIR + '/'\n",
        "\n",
        "# Print directory paths\n",
        "print(\"Raw Videos Directory:\", raw_data_dir)\n",
        "print(\"Frames Directory:\", FRAMES_DIR)\n",
        "print(\"Annotations Directory:\", FRAME_LABELS_FOLDER)\n",
        "print(\"Training Data Directory:\", training_data_dir)\n",
        "print(\"Checkpoint Directory:\", checkpoint_dir)\n",
        "\n",
        "!ls /content/MyDrive/MyDrive/autosynthda/action-recognition/\n",
        "pri_dir      = Path(\"/content/MyDrive/MyDrive/autosynthda/action-recognition\")\n",
        "raw_data_dir = pri_dir / \"raw_data\"\n",
        "\n",
        "for p in (pri_dir, raw_data_dir):\n",
        "    p = Path(p)                       # ← guarantees a Path instance\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"{p} does not exist.\")\n",
        "    if not p.is_dir():\n",
        "        raise NotADirectoryError(f\"{p} exists but is not a directory.\")\n",
        "\n",
        "pri_dir      = Path(\"/content/MyDrive/MyDrive/autosynthda/action-recognition\")\n",
        "raw_data_dir = pri_dir / \"raw_data\"            # this folder has train/val/test inside\n",
        "FOLDS        = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "print(\"Root project dir :\", pri_dir)\n",
        "print(\"Raw videos dir   :\", raw_data_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlKZN4ZjOn8F"
      },
      "outputs": [],
      "source": [
        "\n",
        "# model variables\n",
        "DATA_TYPE = \"kinetics\"\n",
        "DATASET_NAME = \"kinetics\"\n",
        "MODEL = \"slowfast\" #c2d, i3d, slow, slowfast\n",
        "FREEZE_BODY = True\n",
        "\n",
        "# transform variables\n",
        "MIN_SIDE_SIZE = 256\n",
        "MAX_SIDE_SIZE = 320\n",
        "CROP_SIZE = 244\n",
        "MEAN = [0.45, 0.45, 0.45]\n",
        "STD = [0.225, 0.225, 0.225]\n",
        "\n",
        "SLOWFAST_ALPHA = 4\n",
        "if MODEL in [\"c2d\",\"i3d\",\"slow\"]:\n",
        "    NUM_FRAMES = 16\n",
        "elif MODEL == \"slowfast\":\n",
        "    NUM_FRAMES = 32\n",
        "CLIP_SAMPLING_RATE = 1\n",
        "CLIP_DURATION = (NUM_FRAMES * CLIP_SAMPLING_RATE)\n",
        "\n",
        "# FPS = 30\n",
        "CLIP_DURATION = NUM_FRAMES # clip duration is in terms of num of frames\n",
        "\n",
        "N_CLASSES = 2 # Change the number of classes here\n",
        "\n",
        "# dataloader variables\n",
        "NUM_WORKERS = 0\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "# training variables\n",
        "N_EPOCHS = 3\n",
        "LEARNING_RATE = 1e-3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr7lBvLZRmuJ",
        "outputId": "123bcd4d-1116-43bb-cb88-177061432aaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7dec9379c690>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# set the random seed\n",
        "RANDOM_SEED = 17\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UClQXF5TSzKb"
      },
      "source": [
        "# Prep Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdAxqNeybKNg"
      },
      "source": [
        "## Define Actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4SgpN9VS1yF",
        "outputId": "a3c8bc31-c807-4950-e366-e187668dc99a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label {\n",
            "  name: \"adl\"\n",
            "  label_id: 0\n",
            "  label_type: human\n",
            "}\n",
            "label {\n",
            "  name: \"fall\"\n",
            "  label_id: 1\n",
            "  label_type: human\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# define action type\n",
        "action_type_dict = {'adl':'human',\n",
        "                    'fall':'human'\n",
        "                    }\n",
        "ACTION_ID_DICT = {0:'adl',1:'fall'}\n",
        "\n",
        "\n",
        "# create a new empty action_filepath\n",
        "action_filepath = os.path.join(FRAME_LABELS_FOLDER,'action_list.pbtxt')\n",
        "if os.path.exists(action_filepath):\n",
        "  os.remove(action_filepath)\n",
        "with open(action_filepath, 'w') as file:\n",
        "  pass\n",
        "\n",
        "\n",
        "\n",
        "# write\n",
        "for action_name, action_type in action_type_dict.items():\n",
        "  action_id = list(action_type_dict).index(action_name)\n",
        "  write_action(action_filepath,action_name,action_id,action_type,tabsize=2)\n",
        "\n",
        "# check\n",
        "with open(action_filepath, 'r') as action_file:\n",
        "    content = action_file.read()\n",
        "    print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGeW1CChnkGI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBuEA_LwbNiP"
      },
      "source": [
        "## Obtain Videos [Random Split]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slOwfCJ2XcQq"
      },
      "outputs": [],
      "source": [
        "# obtain video information\n",
        "#df_videoinfo = pd.DataFrame()\n",
        "#vid_id = 0\n",
        "\n",
        "#action_names = glob.glob(os.path.join(raw_data_dir,\"*\"))\n",
        "#action_names = [os.path.basename(action_name) for action_name in action_names]\n",
        "\n",
        "#for action_name in action_names:\n",
        " # action_dir = os.path.join(raw_data_dir,action_name)\n",
        " # video_paths = glob.glob(os.path.join(action_dir,\"*\"))\n",
        " # for video_path in video_paths:\n",
        " #   videoinfo = get_videoinfo(video_path)\n",
        " #   videoinfo['action_name'] = action_name\n",
        " #   videoinfo['video_path'] = video_path\n",
        " #   videoinfo['vid_id'] = vid_id\n",
        " #   videoinfo['action_id'] = list(action_type_dict).index(action_name)\n",
        "\n",
        "  #  df_dict = pd.DataFrame.from_dict([videoinfo])\n",
        "  #  df_videoinfo = pd.concat([df_videoinfo,df_dict],ignore_index=True)\n",
        "\n",
        "  #  vid_id += 1\n",
        "\n",
        "# rearrange columns\n",
        "#df_videoinfo = df_videoinfo[['vid_id','video_path','fps','no_images','frameSize','action_name','action_id']]\n",
        "#df_videoinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJTEErmua6Oj"
      },
      "outputs": [],
      "source": [
        "# remove videos that has fewer frames that FRAMES_THRES\n",
        "#df_videoinfo = df_videoinfo.loc[df_videoinfo['no_images']>NUM_FRAMES]\n",
        "#df_videoinfo.reset_index(inplace=True,drop=True)\n",
        "#df_videoinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rex6aNA5Y_Vj"
      },
      "outputs": [],
      "source": [
        "# check number of videos\n",
        "#for action_name in action_names:\n",
        "  #num_vids = len(df_videoinfo[df_videoinfo['action_name']==action_name])\n",
        "  #print(action_name,num_vids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCr7VKsKbFxr"
      },
      "source": [
        "## Create Train Val Test Split [Random Split]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPGQmW4gVLBz"
      },
      "outputs": [],
      "source": [
        "# train val test split\n",
        "#split_df, X_train, X_test = split(df_videoinfo,'action_id',0.2,'train','test')\n",
        "#split_df, X_train, X_val = split(X_train,'action_id',0.2,'train','val')\n",
        "\n",
        "# create new df_videoinfo\n",
        "#df_videoinfo = pd.concat([X_train,X_val,X_test],ignore_index=True)\n",
        "#df_videoinfo = df_videoinfo[['vid_id','video_path','fps','no_images','frameSize','action_name','action_id','fold']]\n",
        "\n",
        "#df_videoinfo.sort_values(by=['vid_id'],axis=0,inplace=True)\n",
        "#df_videoinfo.reset_index(inplace=True,drop=True)\n",
        "#df_videoinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZP_wObVVfGO"
      },
      "outputs": [],
      "source": [
        "# save\n",
        "#df_videoinfo.to_csv(os.path.join(training_data_dir,'video_info.csv'),index=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uJczSjQc6Zz"
      },
      "source": [
        "## Obtain Videos [Fixed Split for AutoSynthDa]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "ACTION_NAME_TO_ID = {\"adl\": 0, \"fall\": 1}\n",
        "\n",
        "rows, vid_id = [], 0\n",
        "for fold in FOLDS:\n",
        "    for action_dir in (raw_data_dir / fold).iterdir():\n",
        "        if not action_dir.is_dir():\n",
        "            continue\n",
        "        action_name = action_dir.name\n",
        "        for video_path in action_dir.glob(\"*\"):\n",
        "            info = get_videoinfo(str(video_path))\n",
        "            info.update({\n",
        "                \"vid_id\"     : vid_id,\n",
        "                \"video_path\" : str(video_path),   # ← contains the fold\n",
        "                \"action_name\": action_name,\n",
        "                \"action_id\"  : ACTION_NAME_TO_ID[action_name],\n",
        "                \"fold\"       : fold\n",
        "            })\n",
        "            rows.append(info)\n",
        "            vid_id += 1\n",
        "\n",
        "\n",
        "\n",
        "#df_videoinfo = df_videoinfo[['vid_id','video_path','fps','no_images','frameSize','action_name','action_id']]"
      ],
      "metadata": {
        "id": "vZ15ytO31F5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Train Val Test Split [Fixed Split for AutoSynthDa]"
      ],
      "metadata": {
        "id": "lZ_PCjpU0i3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_videoinfo = (pd.DataFrame(df_rows)\n",
        "                  #.loc[lambda d: d[\"no_images\"] > NUM_FRAMES]   # keep long enough\n",
        "                  #.reset_index(drop=True)\n",
        "                  #.loc[:, ['vid_id', 'video_path', 'fps', 'no_images',\n",
        "                          #'frameSize', 'action_name', 'action_id', 'fold']])\n",
        "\n",
        "FOLDS = [\"train\", \"val\", \"test\"]          # the three constant splits\n",
        "\n",
        "# ── 1.  keep only videos with enough frames, *per fold* ────────────────\n",
        "df_videoinfo = (pd.DataFrame(rows)\n",
        "                  .loc[lambda d: d[\"no_images\"] > NUM_FRAMES]\n",
        "                  .reset_index(drop=True))\n",
        "\n",
        "pri_dir            = Path(\"/content/MyDrive/MyDrive/autosynthda/action-recognition\")\n",
        "training_data_dir  = pri_dir / \"training_data\"         # ← now a Path object\n",
        "\n",
        "df_videoinfo.to_csv(training_data_dir / \"video_info.csv\", index=False)\n",
        "\n",
        "for fold in FOLDS:\n",
        "    print(df_videoinfo.query(\"fold == @fold\")[\"video_path\"].head().tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HeX4dpH1Eho",
        "outputId": "418f46f5-243a-44c3-97fb-ab7a5aa109ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/02.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/03.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/01.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/04.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/07.mp4']\n",
            "['/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/val/adl/11.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/val/adl/12.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/val/fall/11.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/val/fall/12.mp4']\n",
            "['/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/test/adl/10.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/test/adl/08.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/test/adl/09.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/test/fall/08.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/test/fall/09.mp4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#action_names = glob.glob(os.path.join(raw_data_dir,\"*\"))\n",
        "#action_names = [os.path.basename(action_name) for action_name in action_names]\n",
        "#for action_name in action_names:\n",
        "  #num_vids = len(df_videoinfo[df_videoinfo['action_name']==action_name])\n",
        "  #print(action_name,num_vids)\n",
        "\n",
        "\n",
        "df_videoinfo\n",
        "#print(df_videoinfo[\"video_path\"].head().tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3lDdDUd9Wvk",
        "outputId": "70dd1750-8ed4-4c19-9c1c-40e9a4b9c746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    no_images        fps    frameSize fourcc  vid_id  \\\n",
              "0         198  29.598477  (1280, 720)   h264       0   \n",
              "1         199  29.748409  (1280, 720)   h264       1   \n",
              "2         245  29.612499  (1280, 720)   h264       2   \n",
              "3         170  29.263422  (1280, 720)   h264       3   \n",
              "4         224  29.719128  (1280, 720)   h264       4   \n",
              "5         314  29.775451  (1280, 720)   h264       5   \n",
              "6         364  29.773833  (1280, 720)   h264       6   \n",
              "7         203  29.567987  (1280, 720)   h264       7   \n",
              "8         153  29.688561  (1280, 720)   h264       8   \n",
              "9         189  29.672659  (1280, 720)   h264       9   \n",
              "10        169  29.663521  (1280, 720)   h264      10   \n",
              "11        146  29.427771  (1280, 720)   h264      11   \n",
              "12        174  29.704830  (1280, 720)   h264      12   \n",
              "13        176  29.721530  (1280, 720)   h264      13   \n",
              "14        277  29.741666  (1280, 720)   h264      14   \n",
              "15        218  29.742685  (1280, 720)   h264      15   \n",
              "16        181  29.684784  (1280, 720)   h264      16   \n",
              "17        200  29.268007  (1280, 720)   h264      17   \n",
              "18        115  29.327508  (1280, 720)   h264      18   \n",
              "19        187  29.732408  (1280, 720)   h264      19   \n",
              "20        147  29.437680  (1280, 720)   h264      20   \n",
              "21        129  29.631785  (1280, 720)   h264      21   \n",
              "22        131  29.231067  (1280, 720)   h264      22   \n",
              "23        133  29.572642  (1280, 720)   h264      23   \n",
              "\n",
              "                                           video_path action_name  action_id  \\\n",
              "0   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "1   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "2   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "3   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "4   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "5   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "6   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "7   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "8   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "9   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "10  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "11  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "12  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "13  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "14  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "15  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "16  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "17  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "18  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "19  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "20  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "21  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "22  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "23  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "\n",
              "     fold  \n",
              "0   train  \n",
              "1   train  \n",
              "2   train  \n",
              "3   train  \n",
              "4   train  \n",
              "5   train  \n",
              "6   train  \n",
              "7   train  \n",
              "8   train  \n",
              "9   train  \n",
              "10  train  \n",
              "11  train  \n",
              "12  train  \n",
              "13  train  \n",
              "14    val  \n",
              "15    val  \n",
              "16    val  \n",
              "17    val  \n",
              "18   test  \n",
              "19   test  \n",
              "20   test  \n",
              "21   test  \n",
              "22   test  \n",
              "23   test  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e6cb090-8115-44b9-91b6-c0524cfec84f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no_images</th>\n",
              "      <th>fps</th>\n",
              "      <th>frameSize</th>\n",
              "      <th>fourcc</th>\n",
              "      <th>vid_id</th>\n",
              "      <th>video_path</th>\n",
              "      <th>action_name</th>\n",
              "      <th>action_id</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198</td>\n",
              "      <td>29.598477</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>199</td>\n",
              "      <td>29.748409</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>245</td>\n",
              "      <td>29.612499</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>170</td>\n",
              "      <td>29.263422</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>3</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224</td>\n",
              "      <td>29.719128</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>4</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>314</td>\n",
              "      <td>29.775451</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>5</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>364</td>\n",
              "      <td>29.773833</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>6</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>203</td>\n",
              "      <td>29.567987</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>7</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>153</td>\n",
              "      <td>29.688561</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>8</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>189</td>\n",
              "      <td>29.672659</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>9</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>169</td>\n",
              "      <td>29.663521</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>10</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>146</td>\n",
              "      <td>29.427771</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>11</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>174</td>\n",
              "      <td>29.704830</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>12</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>176</td>\n",
              "      <td>29.721530</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>13</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>277</td>\n",
              "      <td>29.741666</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>14</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>218</td>\n",
              "      <td>29.742685</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>15</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>181</td>\n",
              "      <td>29.684784</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>16</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>200</td>\n",
              "      <td>29.268007</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>17</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>115</td>\n",
              "      <td>29.327508</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>18</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>187</td>\n",
              "      <td>29.732408</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>19</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>147</td>\n",
              "      <td>29.437680</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>20</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>129</td>\n",
              "      <td>29.631785</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>21</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>131</td>\n",
              "      <td>29.231067</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>22</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>133</td>\n",
              "      <td>29.572642</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>23</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e6cb090-8115-44b9-91b6-c0524cfec84f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e6cb090-8115-44b9-91b6-c0524cfec84f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e6cb090-8115-44b9-91b6-c0524cfec84f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5f7f2b70-18f8-4139-ae3e-48d814909fe6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f7f2b70-18f8-4139-ae3e-48d814909fe6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5f7f2b70-18f8-4139-ae3e-48d814909fe6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_efbf4552-c8e8-400c-911a-cdc7a4ddaaa3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_videoinfo')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_efbf4552-c8e8-400c-911a-cdc7a4ddaaa3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_videoinfo');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_videoinfo",
              "summary": "{\n  \"name\": \"df_videoinfo\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"no_images\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 115,\n        \"max\": 364,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          153,\n          181,\n          198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17417537489546128,\n        \"min\": 29.23106674798804,\n        \"max\": 29.775451373084508,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          29.688561172019018,\n          29.684783678289108,\n          29.598477223124682\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frameSize\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          [\n            1280,\n            720\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fourcc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"h264\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/fall/07.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count videos and double check folders"
      ],
      "metadata": {
        "id": "YspkQdR7MmEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = (\n",
        "    df_videoinfo\n",
        "      .groupby([\"action_name\", \"fold\"])   # multi-index: class & split\n",
        "      .size()                             # how many rows (i.e. videos)\n",
        "      .unstack(fill_value=0)              # columns → train / val / test\n",
        "      .assign(total=lambda d: d.sum(1))   # optional total per class\n",
        "      .sort_index()                       # alphabetical by class name\n",
        ")\n",
        "\n",
        "print(summary)        # nice table view"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE2_KP8bMqsu",
        "outputId": "5ab87472-cdf7-459b-c4c6-6f60cfaed8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold         test  train  val  total\n",
            "action_name                         \n",
            "adl             3      7    2     12\n",
            "fall            3      7    2     12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Frames_dir [all]"
      ],
      "metadata": {
        "id": "9eayGf5X0qZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI7jTJgqVqRZ",
        "outputId": "458d377c-29d0-416b-abbb-db9c60b4a6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MyDrive/MyDrive/autosynthda/action-recognition/training_data\n",
            "['/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/02.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/03.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/01.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/04.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/07.mp4']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    no_images        fps    frameSize fourcc  vid_id  \\\n",
              "0         198  29.598477  (1280, 720)   h264       0   \n",
              "1         199  29.748409  (1280, 720)   h264       1   \n",
              "2         245  29.612499  (1280, 720)   h264       2   \n",
              "3         170  29.263422  (1280, 720)   h264       3   \n",
              "4         224  29.719128  (1280, 720)   h264       4   \n",
              "5         314  29.775451  (1280, 720)   h264       5   \n",
              "6         364  29.773833  (1280, 720)   h264       6   \n",
              "7         203  29.567987  (1280, 720)   h264       7   \n",
              "8         153  29.688561  (1280, 720)   h264       8   \n",
              "9         189  29.672659  (1280, 720)   h264       9   \n",
              "10        169  29.663521  (1280, 720)   h264      10   \n",
              "11        146  29.427771  (1280, 720)   h264      11   \n",
              "12        174  29.704830  (1280, 720)   h264      12   \n",
              "13        176  29.721530  (1280, 720)   h264      13   \n",
              "14        277  29.741666  (1280, 720)   h264      14   \n",
              "15        218  29.742685  (1280, 720)   h264      15   \n",
              "16        181  29.684784  (1280, 720)   h264      16   \n",
              "17        200  29.268007  (1280, 720)   h264      17   \n",
              "18        115  29.327508  (1280, 720)   h264      18   \n",
              "19        187  29.732408  (1280, 720)   h264      19   \n",
              "20        147  29.437680  (1280, 720)   h264      20   \n",
              "21        129  29.631785  (1280, 720)   h264      21   \n",
              "22        131  29.231067  (1280, 720)   h264      22   \n",
              "23        133  29.572642  (1280, 720)   h264      23   \n",
              "\n",
              "                                           video_path action_name  action_id  \\\n",
              "0   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "1   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "2   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "3   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "4   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "5   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "6   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "7   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "8   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "9   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "10  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "11  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "12  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "13  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "14  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "15  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "16  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "17  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "18  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "19  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "20  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "21  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "22  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "23  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "\n",
              "     fold  \n",
              "0   train  \n",
              "1   train  \n",
              "2   train  \n",
              "3   train  \n",
              "4   train  \n",
              "5   train  \n",
              "6   train  \n",
              "7   train  \n",
              "8   train  \n",
              "9   train  \n",
              "10  train  \n",
              "11  train  \n",
              "12  train  \n",
              "13  train  \n",
              "14    val  \n",
              "15    val  \n",
              "16    val  \n",
              "17    val  \n",
              "18   test  \n",
              "19   test  \n",
              "20   test  \n",
              "21   test  \n",
              "22   test  \n",
              "23   test  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95df6208-6085-4cf5-9f4c-fffb41e6ae87\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no_images</th>\n",
              "      <th>fps</th>\n",
              "      <th>frameSize</th>\n",
              "      <th>fourcc</th>\n",
              "      <th>vid_id</th>\n",
              "      <th>video_path</th>\n",
              "      <th>action_name</th>\n",
              "      <th>action_id</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198</td>\n",
              "      <td>29.598477</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>199</td>\n",
              "      <td>29.748409</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>245</td>\n",
              "      <td>29.612499</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>170</td>\n",
              "      <td>29.263422</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>3</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224</td>\n",
              "      <td>29.719128</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>4</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>314</td>\n",
              "      <td>29.775451</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>5</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>364</td>\n",
              "      <td>29.773833</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>6</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>203</td>\n",
              "      <td>29.567987</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>7</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>153</td>\n",
              "      <td>29.688561</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>8</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>189</td>\n",
              "      <td>29.672659</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>9</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>169</td>\n",
              "      <td>29.663521</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>10</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>146</td>\n",
              "      <td>29.427771</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>11</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>174</td>\n",
              "      <td>29.704830</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>12</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>176</td>\n",
              "      <td>29.721530</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>13</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>277</td>\n",
              "      <td>29.741666</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>14</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>218</td>\n",
              "      <td>29.742685</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>15</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>181</td>\n",
              "      <td>29.684784</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>16</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>200</td>\n",
              "      <td>29.268007</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>17</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>115</td>\n",
              "      <td>29.327508</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>18</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>187</td>\n",
              "      <td>29.732408</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>19</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>147</td>\n",
              "      <td>29.437680</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>20</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>129</td>\n",
              "      <td>29.631785</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>21</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>131</td>\n",
              "      <td>29.231067</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>22</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>133</td>\n",
              "      <td>29.572642</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>23</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95df6208-6085-4cf5-9f4c-fffb41e6ae87')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95df6208-6085-4cf5-9f4c-fffb41e6ae87 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95df6208-6085-4cf5-9f4c-fffb41e6ae87');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c961c6c0-209e-46ad-897b-6b0f22abf34d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c961c6c0-209e-46ad-897b-6b0f22abf34d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c961c6c0-209e-46ad-897b-6b0f22abf34d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_76d3c2bd-950f-472d-b988-4da9e08bfee6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_videoinfo')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_76d3c2bd-950f-472d-b988-4da9e08bfee6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_videoinfo');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_videoinfo",
              "summary": "{\n  \"name\": \"df_videoinfo\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"no_images\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 115,\n        \"max\": 364,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          153,\n          181,\n          198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17417537489546098,\n        \"min\": 29.23106674798804,\n        \"max\": 29.775451373084508,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          29.688561172019018,\n          29.684783678289108,\n          29.59847722312468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frameSize\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"(1280, 720)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fourcc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"h264\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/fall/07.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# read video info\n",
        "print(training_data_dir)\n",
        "df_videoinfo = pd.read_csv(os.path.join(training_data_dir,'video_info.csv'))\n",
        "\n",
        "print(df_videoinfo[\"video_path\"].head().tolist())\n",
        "df_videoinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "bad = [p for p in df_videoinfo[\"video_path\"] if not Path(p).exists()]\n",
        "print(f\"{len(bad)=}\")\n",
        "print(bad[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le8Q0YmQBu1g",
        "outputId": "08001290-d870-48c2-b898-1382a9b9831d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(bad)=0\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4EB3vg5c-G8",
        "outputId": "2b4dcf28-b426-4aae-ed42-ca80885b4852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 1 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 198/198 [00:03<00:00, 54.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 2 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 199/199 [00:04<00:00, 44.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 3 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 245/245 [00:04<00:00, 58.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 4 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170/170 [00:03<00:00, 56.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 5 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224/224 [00:04<00:00, 45.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 6 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 314/314 [00:05<00:00, 57.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 7 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 364/364 [00:07<00:00, 49.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 8 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 203/203 [00:03<00:00, 55.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 9 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 153/153 [00:02<00:00, 62.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 10 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 189/189 [00:03<00:00, 61.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 11 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169/169 [00:03<00:00, 52.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 12 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 146/146 [00:04<00:00, 32.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 13 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174/174 [00:03<00:00, 52.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 14 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 176/176 [00:02<00:00, 63.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 15 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 277/277 [00:05<00:00, 49.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 16 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 218/218 [00:03<00:00, 66.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 17 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 181/181 [00:02<00:00, 65.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 18 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:02<00:00, 66.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 19 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 115/115 [00:02<00:00, 43.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 20 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 187/187 [00:03<00:00, 55.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 21 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 147/147 [00:02<00:00, 66.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 22 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 129/129 [00:02<00:00, 64.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 23 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131/131 [00:01<00:00, 68.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images for video 24 of 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 133/133 [00:02<00:00, 65.80it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     vid_id frame_id                                training_frame_path\n",
              "0         0        0  /content/MyDrive/MyDrive/autosynthda/action-re...\n",
              "1         0        1  /content/MyDrive/MyDrive/autosynthda/action-re...\n",
              "2         0        2  /content/MyDrive/MyDrive/autosynthda/action-re...\n",
              "3         0        3  /content/MyDrive/MyDrive/autosynthda/action-re...\n",
              "4         0        4  /content/MyDrive/MyDrive/autosynthda/action-re...\n",
              "...     ...      ...                                                ...\n",
              "4637     23      128  /content/MyDrive/MyDrive/autosynthda/action-re...\n",
              "4638     23      129  /content/MyDrive/MyDrive/autosynthda/action-re...\n",
              "4639     23      130  /content/MyDrive/MyDrive/autosynthda/action-re...\n",
              "4640     23      131  /content/MyDrive/MyDrive/autosynthda/action-re...\n",
              "4641     23      132  /content/MyDrive/MyDrive/autosynthda/action-re...\n",
              "\n",
              "[4642 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed797de3-0296-4d99-80bf-64d1bc433fe2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vid_id</th>\n",
              "      <th>frame_id</th>\n",
              "      <th>training_frame_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4637</th>\n",
              "      <td>23</td>\n",
              "      <td>128</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4638</th>\n",
              "      <td>23</td>\n",
              "      <td>129</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4639</th>\n",
              "      <td>23</td>\n",
              "      <td>130</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4640</th>\n",
              "      <td>23</td>\n",
              "      <td>131</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4641</th>\n",
              "      <td>23</td>\n",
              "      <td>132</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4642 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed797de3-0296-4d99-80bf-64d1bc433fe2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed797de3-0296-4d99-80bf-64d1bc433fe2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed797de3-0296-4d99-80bf-64d1bc433fe2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dea464e2-3628-40f8-9461-80a765f66e9c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dea464e2-3628-40f8-9461-80a765f66e9c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dea464e2-3628-40f8-9461-80a765f66e9c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_73256e5b-f00f-425b-8c6f-2c108c2596c3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_frame_info')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_73256e5b-f00f-425b-8c6f-2c108c2596c3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_frame_info');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_frame_info",
              "summary": "{\n  \"name\": \"df_frame_info\",\n  \"rows\": 4642,\n  \"fields\": [\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          8,\n          16,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 363,\n        \"num_unique_values\": 364,\n        \"samples\": [\n          193,\n          33,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"training_frame_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4642,\n        \"samples\": [\n          \"/content/MyDrive/MyDrive/autosynthda/action-recognition/training_data/frames/6/117.jpg\",\n          \"/content/MyDrive/MyDrive/autosynthda/action-recognition/training_data/frames/7/89.jpg\",\n          \"/content/MyDrive/MyDrive/autosynthda/action-recognition/training_data/frames/13/71.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "df_videoinfo\n",
        "df_frame_info = create_frames_dir(df_videoinfo,FRAMES_DIR)\n",
        "df_frame_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfbg7QiTU17p"
      },
      "outputs": [],
      "source": [
        "df_frame_info.to_csv(os.path.join(training_data_dir,'frame_info.csv'),index=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysRr_Xm5VFtN"
      },
      "source": [
        "## Prep frame_lists_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LYmkcMLVlj1",
        "outputId": "e63eec39-ad9c-4c89-bbc7-3c3432a686f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    no_images        fps    frameSize fourcc  vid_id  \\\n",
              "0         198  29.598477  (1280, 720)   h264       0   \n",
              "1         199  29.748409  (1280, 720)   h264       1   \n",
              "2         245  29.612499  (1280, 720)   h264       2   \n",
              "3         170  29.263422  (1280, 720)   h264       3   \n",
              "4         224  29.719128  (1280, 720)   h264       4   \n",
              "5         314  29.775451  (1280, 720)   h264       5   \n",
              "6         364  29.773833  (1280, 720)   h264       6   \n",
              "7         203  29.567987  (1280, 720)   h264       7   \n",
              "8         153  29.688561  (1280, 720)   h264       8   \n",
              "9         189  29.672659  (1280, 720)   h264       9   \n",
              "10        169  29.663521  (1280, 720)   h264      10   \n",
              "11        146  29.427771  (1280, 720)   h264      11   \n",
              "12        174  29.704830  (1280, 720)   h264      12   \n",
              "13        176  29.721530  (1280, 720)   h264      13   \n",
              "14        277  29.741666  (1280, 720)   h264      14   \n",
              "15        218  29.742685  (1280, 720)   h264      15   \n",
              "16        181  29.684784  (1280, 720)   h264      16   \n",
              "17        200  29.268007  (1280, 720)   h264      17   \n",
              "18        115  29.327508  (1280, 720)   h264      18   \n",
              "19        187  29.732408  (1280, 720)   h264      19   \n",
              "20        147  29.437680  (1280, 720)   h264      20   \n",
              "21        129  29.631785  (1280, 720)   h264      21   \n",
              "22        131  29.231067  (1280, 720)   h264      22   \n",
              "23        133  29.572642  (1280, 720)   h264      23   \n",
              "\n",
              "                                           video_path action_name  action_id  \\\n",
              "0   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "1   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "2   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "3   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "4   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "5   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "6   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "7   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "8   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "9   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "10  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "11  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "12  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "13  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "14  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "15  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "16  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "17  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "18  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "19  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "20  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "21  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "22  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "23  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "\n",
              "     fold  \n",
              "0   train  \n",
              "1   train  \n",
              "2   train  \n",
              "3   train  \n",
              "4   train  \n",
              "5   train  \n",
              "6   train  \n",
              "7   train  \n",
              "8   train  \n",
              "9   train  \n",
              "10  train  \n",
              "11  train  \n",
              "12  train  \n",
              "13  train  \n",
              "14    val  \n",
              "15    val  \n",
              "16    val  \n",
              "17    val  \n",
              "18   test  \n",
              "19   test  \n",
              "20   test  \n",
              "21   test  \n",
              "22   test  \n",
              "23   test  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-798245aa-1062-4f1b-8d7f-4ff95fb9f90b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no_images</th>\n",
              "      <th>fps</th>\n",
              "      <th>frameSize</th>\n",
              "      <th>fourcc</th>\n",
              "      <th>vid_id</th>\n",
              "      <th>video_path</th>\n",
              "      <th>action_name</th>\n",
              "      <th>action_id</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198</td>\n",
              "      <td>29.598477</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>199</td>\n",
              "      <td>29.748409</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>245</td>\n",
              "      <td>29.612499</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>170</td>\n",
              "      <td>29.263422</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>3</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224</td>\n",
              "      <td>29.719128</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>4</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>314</td>\n",
              "      <td>29.775451</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>5</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>364</td>\n",
              "      <td>29.773833</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>6</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>203</td>\n",
              "      <td>29.567987</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>7</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>153</td>\n",
              "      <td>29.688561</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>8</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>189</td>\n",
              "      <td>29.672659</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>9</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>169</td>\n",
              "      <td>29.663521</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>10</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>146</td>\n",
              "      <td>29.427771</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>11</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>174</td>\n",
              "      <td>29.704830</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>12</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>176</td>\n",
              "      <td>29.721530</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>13</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>277</td>\n",
              "      <td>29.741666</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>14</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>218</td>\n",
              "      <td>29.742685</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>15</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>181</td>\n",
              "      <td>29.684784</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>16</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>200</td>\n",
              "      <td>29.268007</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>17</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>115</td>\n",
              "      <td>29.327508</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>18</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>187</td>\n",
              "      <td>29.732408</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>19</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>147</td>\n",
              "      <td>29.437680</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>20</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>129</td>\n",
              "      <td>29.631785</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>21</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>131</td>\n",
              "      <td>29.231067</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>22</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>133</td>\n",
              "      <td>29.572642</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>23</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-798245aa-1062-4f1b-8d7f-4ff95fb9f90b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-798245aa-1062-4f1b-8d7f-4ff95fb9f90b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-798245aa-1062-4f1b-8d7f-4ff95fb9f90b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dde5d826-5f2a-4e28-b3e6-4d6b9d06e2d2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dde5d826-5f2a-4e28-b3e6-4d6b9d06e2d2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dde5d826-5f2a-4e28-b3e6-4d6b9d06e2d2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1997368b-68d4-44c5-bf06-1e149fc3cfea\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_videoinfo')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1997368b-68d4-44c5-bf06-1e149fc3cfea button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_videoinfo');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_videoinfo",
              "summary": "{\n  \"name\": \"df_videoinfo\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"no_images\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 115,\n        \"max\": 364,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          153,\n          181,\n          198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17417537489546098,\n        \"min\": 29.23106674798804,\n        \"max\": 29.775451373084508,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          29.688561172019018,\n          29.684783678289108,\n          29.59847722312468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frameSize\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"(1280, 720)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fourcc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"h264\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/fall/07.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# read video info\n",
        "df_videoinfo = pd.read_csv(os.path.join(training_data_dir,'video_info.csv'))\n",
        "df_videoinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw_Gx7f0Vv_S",
        "outputId": "4f709478-010c-4d09-9919-448800658a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:01<00:00,  8.07it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     vid_id frame_id   rel_path\n",
              "0         0        0    0/0.jpg\n",
              "1         0        1    0/1.jpg\n",
              "2         0       10   0/10.jpg\n",
              "3         0      100  0/100.jpg\n",
              "4         0      101  0/101.jpg\n",
              "...     ...      ...        ...\n",
              "2929     13       95  13/95.jpg\n",
              "2930     13       96  13/96.jpg\n",
              "2931     13       97  13/97.jpg\n",
              "2932     13       98  13/98.jpg\n",
              "2933     13       99  13/99.jpg\n",
              "\n",
              "[2934 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2da57b8e-95cd-4fa6-b2c4-3a37aa55cabc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vid_id</th>\n",
              "      <th>frame_id</th>\n",
              "      <th>rel_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0/0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0/10.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0/100.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>0/101.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>13</td>\n",
              "      <td>95</td>\n",
              "      <td>13/95.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>13</td>\n",
              "      <td>96</td>\n",
              "      <td>13/96.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>13</td>\n",
              "      <td>97</td>\n",
              "      <td>13/97.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>13</td>\n",
              "      <td>98</td>\n",
              "      <td>13/98.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2933</th>\n",
              "      <td>13</td>\n",
              "      <td>99</td>\n",
              "      <td>13/99.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2934 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2da57b8e-95cd-4fa6-b2c4-3a37aa55cabc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2da57b8e-95cd-4fa6-b2c4-3a37aa55cabc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2da57b8e-95cd-4fa6-b2c4-3a37aa55cabc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c15733b8-2092-4536-8013-ae7644c6affb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c15733b8-2092-4536-8013-ae7644c6affb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c15733b8-2092-4536-8013-ae7644c6affb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_56bbc09d-60ae-4af5-a973-002fd128b471\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_56bbc09d-60ae-4af5-a973-002fd128b471 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 2934,\n  \"fields\": [\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 13,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          9,\n          11,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 363,\n        \"num_unique_values\": 364,\n        \"samples\": [\n          95,\n          128,\n          111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2934,\n        \"samples\": [\n          \"10/81.jpg\",\n          \"12/12.jpg\",\n          \"13/89.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# create train.tsv\n",
        "train_df = df_videoinfo[df_videoinfo['fold']=='train']\n",
        "df_train = create_frame_lists_csv(train_df)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsfNbclzYGah",
        "outputId": "b1b89988-1f89-4c20-918b-39408673f960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.83it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    vid_id frame_id    rel_path\n",
              "0       14        0    14/0.jpg\n",
              "1       14        1    14/1.jpg\n",
              "2       14       10   14/10.jpg\n",
              "3       14      100  14/100.jpg\n",
              "4       14      101  14/101.jpg\n",
              "..     ...      ...         ...\n",
              "871     17       95   17/95.jpg\n",
              "872     17       96   17/96.jpg\n",
              "873     17       97   17/97.jpg\n",
              "874     17       98   17/98.jpg\n",
              "875     17       99   17/99.jpg\n",
              "\n",
              "[876 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47222689-18ba-4989-b04f-48d1c8e9a413\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vid_id</th>\n",
              "      <th>frame_id</th>\n",
              "      <th>rel_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>14/0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>14/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>14/10.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>100</td>\n",
              "      <td>14/100.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>101</td>\n",
              "      <td>14/101.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>17</td>\n",
              "      <td>95</td>\n",
              "      <td>17/95.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>17</td>\n",
              "      <td>96</td>\n",
              "      <td>17/96.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>17</td>\n",
              "      <td>97</td>\n",
              "      <td>17/97.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>17</td>\n",
              "      <td>98</td>\n",
              "      <td>17/98.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>17</td>\n",
              "      <td>99</td>\n",
              "      <td>17/99.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>876 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47222689-18ba-4989-b04f-48d1c8e9a413')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47222689-18ba-4989-b04f-48d1c8e9a413 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47222689-18ba-4989-b04f-48d1c8e9a413');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-11c9e850-99a6-437c-b6b0-fecabf8c490e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11c9e850-99a6-437c-b6b0-fecabf8c490e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-11c9e850-99a6-437c-b6b0-fecabf8c490e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_614e332f-0054-4980-90b9-6db2114f19f4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_val')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_614e332f-0054-4980-90b9-6db2114f19f4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_val');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_val",
              "summary": "{\n  \"name\": \"df_val\",\n  \"rows\": 876,\n  \"fields\": [\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 14,\n        \"max\": 17,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          15,\n          17,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 276,\n        \"num_unique_values\": 277,\n        \"samples\": [\n          125,\n          211,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 876,\n        \"samples\": [\n          \"15/178.jpg\",\n          \"16/80.jpg\",\n          \"17/56.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# create val.tsv\n",
        "val = df_videoinfo[df_videoinfo['fold']=='val']\n",
        "df_val = create_frame_lists_csv(val)\n",
        "df_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDlvFkWsYICL",
        "outputId": "181b2613-4e41-4f6b-c969-eb1455c9bd0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 11.18it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    vid_id frame_id    rel_path\n",
              "0       18        0    18/0.jpg\n",
              "1       18        1    18/1.jpg\n",
              "2       18       10   18/10.jpg\n",
              "3       18      100  18/100.jpg\n",
              "4       18      101  18/101.jpg\n",
              "..     ...      ...         ...\n",
              "837     23       95   23/95.jpg\n",
              "838     23       96   23/96.jpg\n",
              "839     23       97   23/97.jpg\n",
              "840     23       98   23/98.jpg\n",
              "841     23       99   23/99.jpg\n",
              "\n",
              "[842 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0b09f8a-4482-44d2-a93b-053ef0cff098\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vid_id</th>\n",
              "      <th>frame_id</th>\n",
              "      <th>rel_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>18/0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>18/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18</td>\n",
              "      <td>10</td>\n",
              "      <td>18/10.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>100</td>\n",
              "      <td>18/100.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>101</td>\n",
              "      <td>18/101.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837</th>\n",
              "      <td>23</td>\n",
              "      <td>95</td>\n",
              "      <td>23/95.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>23</td>\n",
              "      <td>96</td>\n",
              "      <td>23/96.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>23</td>\n",
              "      <td>97</td>\n",
              "      <td>23/97.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>23</td>\n",
              "      <td>98</td>\n",
              "      <td>23/98.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>23</td>\n",
              "      <td>99</td>\n",
              "      <td>23/99.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>842 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0b09f8a-4482-44d2-a93b-053ef0cff098')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e0b09f8a-4482-44d2-a93b-053ef0cff098 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e0b09f8a-4482-44d2-a93b-053ef0cff098');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-89b6a5e5-7b12-48b3-b306-3d3b4bad801b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89b6a5e5-7b12-48b3-b306-3d3b4bad801b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-89b6a5e5-7b12-48b3-b306-3d3b4bad801b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_28839c4c-d2d3-4b8c-9bdc-4c90869552c7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_28839c4c-d2d3-4b8c-9bdc-4c90869552c7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 842,\n  \"fields\": [\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 18,\n        \"max\": 23,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          18,\n          19,\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 186,\n        \"num_unique_values\": 187,\n        \"samples\": [\n          185,\n          66,\n          45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 842,\n        \"samples\": [\n          \"21/22.jpg\",\n          \"19/20.jpg\",\n          \"22/20.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# create test.tsv\n",
        "test = df_videoinfo[df_videoinfo['fold']=='test']\n",
        "df_test = create_frame_lists_csv(test)\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uwbrm5MrYNuS"
      },
      "outputs": [],
      "source": [
        "# save\n",
        "df_train.to_csv(os.path.join(FRAME_PATHS_FOLDER,'train.tsv'),index=0,header=False,sep=\"\\t\")\n",
        "df_val.to_csv(os.path.join(FRAME_PATHS_FOLDER,'val.tsv'),index=0,header=False,sep=\"\\t\")\n",
        "df_test.to_csv(os.path.join(FRAME_PATHS_FOLDER,'test.tsv'),index=0,header=False,sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4tqGLLeYfoX"
      },
      "source": [
        "## Prep annotations_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnL-qIIBYhrq",
        "outputId": "ac6d6508-f458-45b7-f559-00b81feabcab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/02.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/03.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/01.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/04.mp4', '/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/adl/07.mp4']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    no_images        fps    frameSize fourcc  vid_id  \\\n",
              "0         198  29.598477  (1280, 720)   h264       0   \n",
              "1         199  29.748409  (1280, 720)   h264       1   \n",
              "2         245  29.612499  (1280, 720)   h264       2   \n",
              "3         170  29.263422  (1280, 720)   h264       3   \n",
              "4         224  29.719128  (1280, 720)   h264       4   \n",
              "5         314  29.775451  (1280, 720)   h264       5   \n",
              "6         364  29.773833  (1280, 720)   h264       6   \n",
              "7         203  29.567987  (1280, 720)   h264       7   \n",
              "8         153  29.688561  (1280, 720)   h264       8   \n",
              "9         189  29.672659  (1280, 720)   h264       9   \n",
              "10        169  29.663521  (1280, 720)   h264      10   \n",
              "11        146  29.427771  (1280, 720)   h264      11   \n",
              "12        174  29.704830  (1280, 720)   h264      12   \n",
              "13        176  29.721530  (1280, 720)   h264      13   \n",
              "14        277  29.741666  (1280, 720)   h264      14   \n",
              "15        218  29.742685  (1280, 720)   h264      15   \n",
              "16        181  29.684784  (1280, 720)   h264      16   \n",
              "17        200  29.268007  (1280, 720)   h264      17   \n",
              "18        115  29.327508  (1280, 720)   h264      18   \n",
              "19        187  29.732408  (1280, 720)   h264      19   \n",
              "20        147  29.437680  (1280, 720)   h264      20   \n",
              "21        129  29.631785  (1280, 720)   h264      21   \n",
              "22        131  29.231067  (1280, 720)   h264      22   \n",
              "23        133  29.572642  (1280, 720)   h264      23   \n",
              "\n",
              "                                           video_path action_name  action_id  \\\n",
              "0   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "1   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "2   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "3   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "4   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "5   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "6   /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "7   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "8   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "9   /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "10  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "11  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "12  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "13  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "14  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "15  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "16  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "17  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "18  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "19  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "20  /content/MyDrive/MyDrive/autosynthda/action-re...         adl          0   \n",
              "21  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "22  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "23  /content/MyDrive/MyDrive/autosynthda/action-re...        fall          1   \n",
              "\n",
              "     fold  \n",
              "0   train  \n",
              "1   train  \n",
              "2   train  \n",
              "3   train  \n",
              "4   train  \n",
              "5   train  \n",
              "6   train  \n",
              "7   train  \n",
              "8   train  \n",
              "9   train  \n",
              "10  train  \n",
              "11  train  \n",
              "12  train  \n",
              "13  train  \n",
              "14    val  \n",
              "15    val  \n",
              "16    val  \n",
              "17    val  \n",
              "18   test  \n",
              "19   test  \n",
              "20   test  \n",
              "21   test  \n",
              "22   test  \n",
              "23   test  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71fd558d-3279-4b15-9814-d2c8452bc2a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no_images</th>\n",
              "      <th>fps</th>\n",
              "      <th>frameSize</th>\n",
              "      <th>fourcc</th>\n",
              "      <th>vid_id</th>\n",
              "      <th>video_path</th>\n",
              "      <th>action_name</th>\n",
              "      <th>action_id</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198</td>\n",
              "      <td>29.598477</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>199</td>\n",
              "      <td>29.748409</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>245</td>\n",
              "      <td>29.612499</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>170</td>\n",
              "      <td>29.263422</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>3</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>224</td>\n",
              "      <td>29.719128</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>4</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>314</td>\n",
              "      <td>29.775451</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>5</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>364</td>\n",
              "      <td>29.773833</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>6</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>203</td>\n",
              "      <td>29.567987</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>7</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>153</td>\n",
              "      <td>29.688561</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>8</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>189</td>\n",
              "      <td>29.672659</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>9</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>169</td>\n",
              "      <td>29.663521</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>10</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>146</td>\n",
              "      <td>29.427771</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>11</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>174</td>\n",
              "      <td>29.704830</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>12</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>176</td>\n",
              "      <td>29.721530</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>13</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>277</td>\n",
              "      <td>29.741666</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>14</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>218</td>\n",
              "      <td>29.742685</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>15</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>181</td>\n",
              "      <td>29.684784</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>16</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>200</td>\n",
              "      <td>29.268007</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>17</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>115</td>\n",
              "      <td>29.327508</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>18</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>187</td>\n",
              "      <td>29.732408</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>19</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>147</td>\n",
              "      <td>29.437680</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>20</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>adl</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>129</td>\n",
              "      <td>29.631785</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>21</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>131</td>\n",
              "      <td>29.231067</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>22</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>133</td>\n",
              "      <td>29.572642</td>\n",
              "      <td>(1280, 720)</td>\n",
              "      <td>h264</td>\n",
              "      <td>23</td>\n",
              "      <td>/content/MyDrive/MyDrive/autosynthda/action-re...</td>\n",
              "      <td>fall</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71fd558d-3279-4b15-9814-d2c8452bc2a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71fd558d-3279-4b15-9814-d2c8452bc2a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71fd558d-3279-4b15-9814-d2c8452bc2a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fcbd1a32-af4c-455d-8a65-49d9ae449f47\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fcbd1a32-af4c-455d-8a65-49d9ae449f47')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fcbd1a32-af4c-455d-8a65-49d9ae449f47 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e7f9361b-2a7a-4618-8887-23923aaca708\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_videoinfo')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e7f9361b-2a7a-4618-8887-23923aaca708 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_videoinfo');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_videoinfo",
              "summary": "{\n  \"name\": \"df_videoinfo\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"no_images\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 115,\n        \"max\": 364,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          153,\n          181,\n          198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17417537489546098,\n        \"min\": 29.23106674798804,\n        \"max\": 29.775451373084508,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          29.688561172019018,\n          29.684783678289108,\n          29.59847722312468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frameSize\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"(1280, 720)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fourcc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"h264\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"/content/MyDrive/MyDrive/autosynthda/action-recognition/raw_data/train/fall/07.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"fall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# import df_video_info\n",
        "df_videoinfo = pd.read_csv(os.path.join(training_data_dir,'video_info.csv'))\n",
        "print(df_videoinfo[\"video_path\"].head().tolist())\n",
        "df_videoinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWPI01W6ZKYM",
        "outputId": "236a5082-165d-43c1-ecbc-53ffba32a959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/14 [00:00<?, ?it/s]/tmp/ipython-input-13-254244972.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df,df_dict],ignore_index=True)\n",
            "100%|██████████| 14/14 [00:01<00:00,  7.72it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     vid_id frame_id  frame_timestamp action_label\n",
              "0         0        0         0.000000            0\n",
              "1         0        1         0.033786            0\n",
              "2         0       10         0.337855            0\n",
              "3         0      100         3.378552            0\n",
              "4         0      101         3.412338            0\n",
              "...     ...      ...              ...          ...\n",
              "2929     13       95         3.196336            1\n",
              "2930     13       96         3.229982            1\n",
              "2931     13       97         3.263627            1\n",
              "2932     13       98         3.297273            1\n",
              "2933     13       99         3.330919            1\n",
              "\n",
              "[2934 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-207b73fa-c67e-42dd-80b9-94ae942bf9f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vid_id</th>\n",
              "      <th>frame_id</th>\n",
              "      <th>frame_timestamp</th>\n",
              "      <th>action_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.033786</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.337855</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>3.378552</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>3.412338</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>13</td>\n",
              "      <td>95</td>\n",
              "      <td>3.196336</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>13</td>\n",
              "      <td>96</td>\n",
              "      <td>3.229982</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>13</td>\n",
              "      <td>97</td>\n",
              "      <td>3.263627</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>13</td>\n",
              "      <td>98</td>\n",
              "      <td>3.297273</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2933</th>\n",
              "      <td>13</td>\n",
              "      <td>99</td>\n",
              "      <td>3.330919</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2934 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-207b73fa-c67e-42dd-80b9-94ae942bf9f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-207b73fa-c67e-42dd-80b9-94ae942bf9f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-207b73fa-c67e-42dd-80b9-94ae942bf9f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8c0385d2-7dde-443c-bca5-af080e3f6e43\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c0385d2-7dde-443c-bca5-af080e3f6e43')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8c0385d2-7dde-443c-bca5-af080e3f6e43 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3121280a-e4e7-4ea6-82d5-ceab9b89c40e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3121280a-e4e7-4ea6-82d5-ceab9b89c40e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 2934,\n  \"fields\": [\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 13,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          9,\n          11,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 363,\n        \"num_unique_values\": 364,\n        \"samples\": [\n          95,\n          128,\n          111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.567229848718355,\n        \"min\": 0.0,\n        \"max\": 12.191913461538462,\n        \"num_unique_values\": 2921,\n        \"samples\": [\n          1.3136372549019608,\n          6.222946469622331,\n          3.1662026143790847\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_label\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# train_predicted_boxes.csv\n",
        "train_df = df_videoinfo[df_videoinfo['fold']=='train']\n",
        "df_train = create_annotations_csv(train_df)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeD-063BcWGI",
        "outputId": "aa98cec4-83c4-4159-aa0d-f863c62fb444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipython-input-13-254244972.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df,df_dict],ignore_index=True)\n",
            "100%|██████████| 4/4 [00:00<00:00,  7.66it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    vid_id frame_id  frame_timestamp action_label\n",
              "0       14        0         0.000000            0\n",
              "1       14        1         0.033623            0\n",
              "2       14       10         0.336229            0\n",
              "3       14      100         3.362286            0\n",
              "4       14      101         3.395909            0\n",
              "..     ...      ...              ...          ...\n",
              "871     17       95         3.245865            1\n",
              "872     17       96         3.280032            1\n",
              "873     17       97         3.314199            1\n",
              "874     17       98         3.348366            1\n",
              "875     17       99         3.382533            1\n",
              "\n",
              "[876 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e9d6d96-eb83-468d-8149-964a0ef29e4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vid_id</th>\n",
              "      <th>frame_id</th>\n",
              "      <th>frame_timestamp</th>\n",
              "      <th>action_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0.033623</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>0.336229</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>100</td>\n",
              "      <td>3.362286</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>101</td>\n",
              "      <td>3.395909</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>17</td>\n",
              "      <td>95</td>\n",
              "      <td>3.245865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>17</td>\n",
              "      <td>96</td>\n",
              "      <td>3.280032</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>17</td>\n",
              "      <td>97</td>\n",
              "      <td>3.314199</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>17</td>\n",
              "      <td>98</td>\n",
              "      <td>3.348366</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>17</td>\n",
              "      <td>99</td>\n",
              "      <td>3.382533</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>876 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e9d6d96-eb83-468d-8149-964a0ef29e4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e9d6d96-eb83-468d-8149-964a0ef29e4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e9d6d96-eb83-468d-8149-964a0ef29e4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-923192db-16bf-4973-bd5d-61f1a4842c9b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-923192db-16bf-4973-bd5d-61f1a4842c9b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-923192db-16bf-4973-bd5d-61f1a4842c9b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1182ff41-872c-4867-a386-208c39e85fc7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_val')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1182ff41-872c-4867-a386-208c39e85fc7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_val');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_val",
              "summary": "{\n  \"name\": \"df_val\",\n  \"rows\": 876,\n  \"fields\": [\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 14,\n        \"max\": 17,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          15,\n          17,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 276,\n        \"num_unique_values\": 277,\n        \"samples\": [\n          125,\n          211,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.306779975037064,\n        \"min\": 0.0,\n        \"max\": 9.279910469314078,\n        \"num_unique_values\": 873,\n        \"samples\": [\n          0.9908429999999999,\n          4.606174617737003,\n          6.522612232415902\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_label\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# val_predicted_boxes.csv\n",
        "val = df_videoinfo[df_videoinfo['fold']=='val']\n",
        "df_val = create_annotations_csv(val)\n",
        "df_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tMDJeI6cbBK",
        "outputId": "30a53db4-de6d-46cc-8548-bcd1c6e98c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]/tmp/ipython-input-13-254244972.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df = pd.concat([out_df,df_dict],ignore_index=True)\n",
            "100%|██████████| 6/6 [00:00<00:00, 12.21it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    vid_id frame_id  frame_timestamp action_label\n",
              "0       18        0         0.000000            0\n",
              "1       18        1         0.034098            0\n",
              "2       18       10         0.340977            0\n",
              "3       18      100         3.409768            0\n",
              "4       18      101         3.443866            0\n",
              "..     ...      ...              ...          ...\n",
              "837     23       95         3.212429            1\n",
              "838     23       96         3.246244            1\n",
              "839     23       97         3.280059            1\n",
              "840     23       98         3.313874            1\n",
              "841     23       99         3.347689            1\n",
              "\n",
              "[842 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5df45d9b-ae65-4222-a1d8-d46e886901ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vid_id</th>\n",
              "      <th>frame_id</th>\n",
              "      <th>frame_timestamp</th>\n",
              "      <th>action_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0.034098</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18</td>\n",
              "      <td>10</td>\n",
              "      <td>0.340977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>100</td>\n",
              "      <td>3.409768</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>101</td>\n",
              "      <td>3.443866</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837</th>\n",
              "      <td>23</td>\n",
              "      <td>95</td>\n",
              "      <td>3.212429</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>23</td>\n",
              "      <td>96</td>\n",
              "      <td>3.246244</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>23</td>\n",
              "      <td>97</td>\n",
              "      <td>3.280059</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>23</td>\n",
              "      <td>98</td>\n",
              "      <td>3.313874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>23</td>\n",
              "      <td>99</td>\n",
              "      <td>3.347689</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>842 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5df45d9b-ae65-4222-a1d8-d46e886901ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5df45d9b-ae65-4222-a1d8-d46e886901ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5df45d9b-ae65-4222-a1d8-d46e886901ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7e93b011-0da2-4b90-94da-d8269e039420\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e93b011-0da2-4b90-94da-d8269e039420')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7e93b011-0da2-4b90-94da-d8269e039420 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_674b293c-32b0-4c8d-9bca-db5886eeed35\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_674b293c-32b0-4c8d-9bca-db5886eeed35 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 842,\n  \"fields\": [\n    {\n      \"column\": \"vid_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 18,\n        \"max\": 23,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          18,\n          19,\n          23\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 186,\n        \"num_unique_values\": 187,\n        \"samples\": [\n          185,\n          66,\n          45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4852280505813227,\n        \"min\": 0.0,\n        \"max\": 6.2558,\n        \"num_unique_values\": 837,\n        \"samples\": [\n          6.188533333333333,\n          2.941908270676692,\n          2.2504469565217393\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action_label\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# test_predicted_boxes.csv\n",
        "test = df_videoinfo[df_videoinfo['fold']=='test']\n",
        "df_test = create_annotations_csv(test)\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T7Us81dcePO"
      },
      "outputs": [],
      "source": [
        "# save\n",
        "df_train.to_csv(os.path.join(FRAME_LABELS_FOLDER,'train_predicted_boxes.csv'),index=0,header=False)\n",
        "df_val.to_csv(os.path.join(FRAME_LABELS_FOLDER,'val_predicted_boxes.csv'),index=0,header=False)\n",
        "df_test.to_csv(os.path.join(FRAME_LABELS_FOLDER,'test_predicted_boxes.csv'),index=0,header=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoqnGv3ENZ39"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOxMqMfIf3JJ"
      },
      "source": [
        "## Create Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SHYhaCif1zs"
      },
      "outputs": [],
      "source": [
        "# create dataloaders\n",
        "train_dataloader = create_dataloader(\"train\")\n",
        "val_dataloader = create_dataloader(\"val\")\n",
        "\n",
        "current_dataloaders = {\"train\": train_dataloader,\n",
        "                      \"val\": val_dataloader}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQBnBd1on7eo"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKnafrB0QBLp",
        "outputId": "30f560f1-6200-4227-e28c-58d392303307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# create model\n",
        "current_model, current_device = create_model(N_CLASSES, model_type=MODEL, freeze_body=FREEZE_BODY)\n",
        "\n",
        "# obtain optimizer and loss\n",
        "current_optimizer = torch.optim.Adam(current_model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unit tests for loaders\n",
        "def _test_loader(dl, name=\"\"):\n",
        "    batch = next(iter(dl))\n",
        "\n",
        "    # Base checks\n",
        "    assert isinstance(batch, dict), f\"{name}: expected dict, got {type(batch)}\"\n",
        "    assert \"video\" in batch and \"label\" in batch, f\"{name}: missing keys {batch.keys()}\"\n",
        "\n",
        "    video = batch[\"video\"]\n",
        "    label = batch[\"label\"]\n",
        "\n",
        "    # Handle single-path vs SlowFast (2-path)\n",
        "    if isinstance(video, list):\n",
        "        assert len(video) == 2, f\"{name}: expected 2 tensors for SlowFast, got {len(video)}\"\n",
        "        slow, fast = video\n",
        "        assert slow.dtype == torch.float32 and fast.dtype == torch.float32, f\"{name}: video dtype not float32\"\n",
        "        vid_shape = [tuple(slow.shape), tuple(fast.shape)]\n",
        "    else:\n",
        "        assert video.dtype == torch.float32, f\"{name}: video dtype not float32\"\n",
        "        vid_shape = tuple(video.shape)\n",
        "\n",
        "    assert label.dtype in (torch.int64, torch.long), f\"{name}: label dtype not int64/long\"\n",
        "\n",
        "    print(f\"✓ {name} loader OK — video {vid_shape}, label {label.shape}\")\n",
        "\n",
        "_test_loader(train_dataloader, \"train\")\n",
        "_test_loader(val_dataloader,   \"val\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oau_g_9vjoVA",
        "outputId": "32c3b6f1-c6ae-4fe8-fd7d-a3564e2b90ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ train loader OK — video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n",
            "✓ val loader OK — video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check what is inside each loader (debugging)\n",
        "\n",
        "import torch, inspect\n",
        "\n",
        "sample_batch = next(iter(current_dataloaders[\"train\"]))\n",
        "\n",
        "print(\"type(batch) :\", type(sample_batch))\n",
        "print(\"tuple length:\", len(sample_batch))\n",
        "\n",
        "for idx, item in enumerate(sample_batch):\n",
        "    if torch.is_tensor(item):\n",
        "        print(f\"[{idx}] tensor  shape={tuple(item.shape)}  dtype={item.dtype}\")\n",
        "    else:\n",
        "        print(f\"[{idx}] {type(item)} → {item if len(str(item)) < 100 else '...'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VIo34-rj90p",
        "outputId": "f4c4daa4-7caf-4273-fe3e-3f6996a9f1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(batch) : <class 'dict'>\n",
            "tuple length: 2\n",
            "[0] <class 'str'> → video\n",
            "[1] <class 'str'> → label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kfDMe55n85Z"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjHVy5PlWYau"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# create output directory\n",
        "current_date_time = datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\")\n",
        "current_output_dir = os.path.join(checkpoint_dir, \"{}\".format(current_date_time))\n",
        "os.makedirs(current_output_dir,exist_ok=True)\n",
        "model_save_dir = os.path.join(current_output_dir, \"saved_models\")\n",
        "create_dir(model_save_dir)\n",
        "model_log_dir = os.path.join(current_output_dir, \"logs\")\n",
        "create_dir(model_log_dir)\n",
        "model_evaluation_dir = os.path.join(current_output_dir, \"model_evaluation\")\n",
        "create_dir(model_evaluation_dir)\n",
        "args_file = os.path.join(current_output_dir, \"args.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-t4EBKsWsZZ"
      },
      "outputs": [],
      "source": [
        "# save current parameters in a json for easier reference in the future\n",
        "params = {\"args_file\": args_file, \"current_date_time\": current_date_time, \"random_seed\": RANDOM_SEED,\n",
        "          \"current_output_dir\": current_output_dir, \"model_save_dir\": model_save_dir, \"model_log_dir\": model_log_dir, \"model_evaluation_dir\": model_evaluation_dir,\n",
        "          \"frame_paths_folder\": FRAME_PATHS_FOLDER, \"frame_labels_folder\": FRAME_LABELS_FOLDER, \"label_map_file\": LABEL_MAP_FILE, \"video_path_prefix\": VIDEO_PATH_PREFIX,\n",
        "          \"data_type\": DATA_TYPE, \"dataset_name\": DATASET_NAME, \"model\": MODEL, \"freeze_body\": FREEZE_BODY, \"min_side_size\": MIN_SIDE_SIZE,  \"max_side_size\": MAX_SIDE_SIZE, \"crop_size\": CROP_SIZE, \"mean\": MEAN, \"std\": STD,\n",
        "          \"num_frames\": NUM_FRAMES, \"clip_sampling_rate\": CLIP_SAMPLING_RATE, \"clip_duration\": CLIP_DURATION,\n",
        "          \"n_classes\": N_CLASSES,\n",
        "          \"num_workers\": NUM_WORKERS, \"batch_size\": BATCH_SIZE,\n",
        "          \"n_epochs\" : N_EPOCHS, \"learning_rate\": LEARNING_RATE}\n",
        "\n",
        "write_args(params, args_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAn20umkyDK_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch.distributed as dist\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"RANK\"] = \"0\"  # Rank of this process\n",
        "os.environ[\"WORLD_SIZE\"] = \"1\"  # Total number of processes\n",
        "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"  # Master node IP (localhost for single-node)\n",
        "os.environ[\"MASTER_PORT\"] = \"29500\"  # Any free port\n",
        "\n",
        "# Initialize process group\n",
        "dist.init_process_group(backend=\"nccl\")  # Change to \"gloo\" for CPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note that the number of clips being more than the number of videos u passed in is normal\n",
        "# Bottom line: the bigger number is normal—the dataset treats every\n",
        "# (start-time, end-time) pair as a separate sample so you can squeeze multiple\n",
        "# training steps out of one long video."
      ],
      "metadata": {
        "id": "-zFZwBNCuASi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GUeebOP0Wxph",
        "outputId": "38878d17-f486-4921-fb9d-9949a2c3a794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_clips: 70\n",
            "batch_size: 1\n",
            "Epoch 1 of 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 1/70 [00:02<02:31,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 0: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/70 [00:04<02:29,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 1: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/70 [00:06<02:10,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 2: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/70 [00:08<02:10,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 3: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/70 [00:09<02:00,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 4: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 6/70 [00:11<01:52,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 5: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/70 [00:12<01:48,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 6: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 8/70 [00:14<01:49,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 7: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/70 [00:17<02:03,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 8: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 10/70 [00:19<01:56,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 9: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/70 [00:20<01:48,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 10: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 12/70 [00:22<01:43,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 11: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 13/70 [00:23<01:38,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 12: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 14/70 [00:25<01:39,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 13: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 15/70 [00:27<01:34,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 14: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 16/70 [00:29<01:38,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 15: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 17/70 [00:31<01:40,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 16: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 18/70 [00:33<01:33,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 17: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 19/70 [00:35<01:33,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 18: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 20/70 [00:36<01:29,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 19: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 21/70 [00:38<01:25,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 20: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 22/70 [00:40<01:22,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 21: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 23/70 [00:42<01:23,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 22: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 24/70 [00:44<01:34,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 23: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 25/70 [00:46<01:27,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 24: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 26/70 [00:48<01:21,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 25: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 27/70 [00:49<01:17,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 26: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 28/70 [00:51<01:12,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 27: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 29/70 [00:53<01:13,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 28: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 30/70 [00:54<01:09,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 29: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 31/70 [00:57<01:13,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 30: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 32/70 [00:58<01:12,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 31: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 33/70 [01:00<01:07,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 32: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 34/70 [01:02<01:06,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 33: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 35/70 [01:04<01:02,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 34: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 36/70 [01:05<00:58,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 35: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 37/70 [01:07<00:55,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 36: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 38/70 [01:09<00:55,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 37: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 39/70 [01:11<01:03,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 38: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 40/70 [01:13<00:57,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 39: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 41/70 [01:15<00:53,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 40: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 42/70 [01:16<00:49,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 41: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 43/70 [01:18<00:47,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 42: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 44/70 [01:20<00:46,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 43: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 45/70 [01:22<00:43,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 44: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 46/70 [01:24<00:45,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 45: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 47/70 [01:26<00:44,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 46: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 48/70 [01:28<00:40,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 47: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 49/70 [01:30<00:39,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 48: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 50/70 [01:31<00:36,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 49: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 51/70 [01:33<00:33,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 50: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 52/70 [01:34<00:30,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 51: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 53/70 [01:36<00:30,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 52: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 54/70 [01:39<00:32,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 53: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 55/70 [01:41<00:28,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 54: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 56/70 [01:42<00:25,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 55: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 57/70 [01:44<00:23,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 56: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 58/70 [01:46<00:20,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 57: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 59/70 [01:48<00:19,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 58: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 60/70 [01:50<00:18,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 59: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 61/70 [01:52<00:18,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 60: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 62/70 [01:54<00:15,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 61: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 63/70 [01:55<00:12,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 62: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 64/70 [01:57<00:11,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 63: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 65/70 [01:59<00:08,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 64: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 66/70 [02:00<00:07,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 65: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 67/70 [02:02<00:05,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 66: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 68/70 [02:04<00:03,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 67: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 69/70 [02:06<00:01,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 68: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 70/70 [02:08<00:00,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 69: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r71it [02:10,  1.77s/it]                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 70: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r72it [02:11,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 71: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r73it [02:13,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 72: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "74it [02:15,  1.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 73: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:08<00:00,  1.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:13<00:00,  1.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:59,  1.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 of 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 1/70 [00:02<03:00,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 0: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/70 [00:04<02:35,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 1: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/70 [00:06<02:13,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 2: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/70 [00:07<02:01,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 3: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/70 [00:10<02:09,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 4: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 6/70 [00:12<02:14,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 5: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/70 [00:14<02:03,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 6: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 8/70 [00:16<02:08,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 7: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/70 [00:18<02:05,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 8: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 10/70 [00:20<02:02,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 9: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/70 [00:22<01:52,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 10: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 12/70 [00:23<01:45,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 11: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 13/70 [00:25<01:39,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 12: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 14/70 [00:26<01:36,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 13: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 15/70 [00:29<01:45,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 14: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 16/70 [00:31<01:48,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 15: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 17/70 [00:33<01:40,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 16: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 18/70 [00:34<01:35,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 17: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 19/70 [00:36<01:31,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 18: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 20/70 [00:38<01:32,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 19: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 21/70 [00:40<01:27,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 20: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 22/70 [00:42<01:26,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 21: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 23/70 [00:44<01:31,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 22: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 24/70 [00:46<01:28,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 23: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 25/70 [00:48<01:27,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 24: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 26/70 [00:49<01:20,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 25: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 27/70 [00:51<01:16,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 26: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 28/70 [00:53<01:13,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 27: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 29/70 [00:54<01:10,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 28: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 30/70 [00:57<01:17,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 29: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 31/70 [00:59<01:15,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 30: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 32/70 [01:00<01:09,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 31: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 33/70 [01:02<01:05,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 32: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 34/70 [01:03<01:02,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 33: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 35/70 [01:05<01:02,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 34: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 36/70 [01:07<00:59,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 35: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 37/70 [01:09<00:59,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 36: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 38/70 [01:11<01:00,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 37: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 39/70 [01:13<00:56,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 38: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 40/70 [01:15<00:56,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 39: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 41/70 [01:16<00:52,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 40: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 42/70 [01:18<00:50,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 41: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 43/70 [01:20<00:47,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 42: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 44/70 [01:22<00:45,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 43: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 45/70 [01:24<00:50,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 44: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 46/70 [01:26<00:47,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 45: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 47/70 [01:28<00:43,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 46: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 48/70 [01:29<00:39,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 47: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 49/70 [01:31<00:36,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 48: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 50/70 [01:33<00:35,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 49: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 51/70 [01:34<00:32,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 50: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 52/70 [01:37<00:33,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 51: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 53/70 [01:39<00:32,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 52: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 54/70 [01:40<00:29,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 53: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 55/70 [01:42<00:28,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 54: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 56/70 [01:44<00:25,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 55: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 57/70 [01:46<00:22,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 56: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 58/70 [01:47<00:20,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 57: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 59/70 [01:49<00:19,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 58: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 60/70 [01:52<00:20,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 59: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 61/70 [01:53<00:17,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 60: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 62/70 [01:55<00:14,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 61: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 63/70 [01:57<00:12,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 62: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 64/70 [01:58<00:10,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 63: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 65/70 [02:00<00:09,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 64: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 66/70 [02:02<00:07,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 65: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 67/70 [02:05<00:05,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 66: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 68/70 [02:06<00:03,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 67: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 69/70 [02:08<00:01,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 68: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:10<00:00,  1.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 69: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:11<00:00,  1.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:15<00:00,  1.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:47<00:00,  1.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 of 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 1/70 [00:02<03:19,  2.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 0: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/70 [00:04<02:42,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 1: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/70 [00:06<02:16,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 2: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/70 [00:08<02:05,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 3: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/70 [00:10<02:04,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 4: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 6/70 [00:12<02:05,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 5: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/70 [00:14<02:00,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 6: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 8/70 [00:16<02:01,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 7: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/70 [00:18<02:05,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 8: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 10/70 [00:20<02:11,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 9: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/70 [00:22<01:58,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 10: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 12/70 [00:24<01:49,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 11: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 13/70 [00:25<01:44,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 12: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 14/70 [00:27<01:40,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 13: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 15/70 [00:31<02:18,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 14: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 16/70 [00:33<02:11,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 15: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 17/70 [00:35<01:56,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 16: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 18/70 [00:37<01:46,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 17: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 19/70 [00:39<01:39,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 18: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 20/70 [00:41<01:38,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 19: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 21/70 [00:42<01:33,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 20: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 22/70 [00:45<01:37,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 21: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 23/70 [00:47<01:34,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 22: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 24/70 [00:48<01:27,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 23: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 25/70 [00:50<01:27,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 24: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 26/70 [00:52<01:21,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 25: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 27/70 [00:54<01:16,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 26: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 28/70 [00:55<01:14,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 27: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 29/70 [00:57<01:17,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 28: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 30/70 [01:00<01:22,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 29: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 31/70 [01:02<01:15,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 30: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 32/70 [01:03<01:10,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 31: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 33/70 [01:05<01:06,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 32: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 34/70 [01:07<01:03,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 33: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 35/70 [01:08<01:03,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 34: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 36/70 [01:11<01:04,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 35: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 37/70 [01:13<01:06,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 36: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 38/70 [01:14<01:00,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 37: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 39/70 [01:16<00:56,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 38: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 40/70 [01:18<00:55,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 39: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 41/70 [01:20<00:52,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 40: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 42/70 [01:21<00:49,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 41: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 43/70 [01:23<00:48,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 42: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 44/70 [01:26<00:50,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 43: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 45/70 [01:28<00:49,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 44: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 46/70 [01:29<00:45,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 45: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 47/70 [01:31<00:41,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 46: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 48/70 [01:33<00:38,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 47: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 49/70 [01:34<00:35,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 48: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 50/70 [01:36<00:35,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 49: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 51/70 [01:38<00:35,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 50: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 52/70 [01:40<00:34,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 51: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 53/70 [01:42<00:31,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 52: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 54/70 [01:43<00:28,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 53: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 55/70 [01:45<00:27,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 54: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 56/70 [01:47<00:24,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 55: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 57/70 [01:49<00:22,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 56: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 58/70 [01:51<00:21,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 57: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 59/70 [01:53<00:20,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 58: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 60/70 [01:55<00:19,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 59: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 61/70 [01:56<00:16,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 60: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 62/70 [01:58<00:14,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 61: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 63/70 [02:00<00:12,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 62: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 64/70 [02:01<00:10,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 63: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 65/70 [02:03<00:08,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 64: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 66/70 [02:05<00:07,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 65: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 67/70 [02:07<00:05,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 66: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 68/70 [02:09<00:03,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 67: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 69/70 [02:11<00:01,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 68: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:13<00:00,  1.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 69: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:11<00:00,  1.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:14<00:00,  1.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:45<00:00,  1.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 of 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 1/70 [00:01<02:15,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 0: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/70 [00:03<02:08,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 1: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/70 [00:05<02:14,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 2: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/70 [00:07<02:11,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 3: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/70 [00:10<02:22,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 4: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 6/70 [00:12<02:07,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 5: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/70 [00:13<01:58,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 6: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 8/70 [00:15<01:50,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 7: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/70 [00:17<01:59,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 8: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 10/70 [00:20<02:16,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 9: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/70 [00:22<02:01,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 10: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 12/70 [00:23<01:51,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 11: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 13/70 [00:25<01:45,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 12: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 14/70 [00:27<01:39,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 13: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 15/70 [00:29<01:41,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 14: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 16/70 [00:30<01:38,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 15: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 17/70 [00:33<01:46,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 16: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 18/70 [00:35<01:43,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 17: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 19/70 [00:37<01:37,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 18: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 20/70 [00:39<01:37,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 19: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 21/70 [00:40<01:32,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 20: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 22/70 [00:42<01:27,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 21: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 23/70 [00:44<01:24,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 22: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 24/70 [00:46<01:29,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 23: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 25/70 [00:49<01:35,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 24: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 26/70 [00:50<01:28,  2.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 25: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 27/70 [00:52<01:21,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 26: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 28/70 [00:54<01:16,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 27: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 29/70 [00:55<01:13,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 28: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 30/70 [00:57<01:15,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 29: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 31/70 [01:00<01:16,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 30: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 32/70 [01:02<01:17,  2.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 31: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 33/70 [01:03<01:11,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 32: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 34/70 [01:05<01:06,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 33: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 35/70 [01:07<01:07,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 34: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 36/70 [01:09<01:03,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 35: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 37/70 [01:11<00:59,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 36: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 38/70 [01:13<00:58,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 37: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 39/70 [01:15<01:00,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 38: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 40/70 [01:17<00:59,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 39: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 41/70 [01:18<00:53,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 40: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 42/70 [01:20<00:50,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 41: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 43/70 [01:22<00:47,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 42: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 44/70 [01:23<00:44,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 43: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 45/70 [01:25<00:44,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 44: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 46/70 [01:27<00:44,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 45: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 47/70 [01:29<00:43,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 46: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 48/70 [01:31<00:39,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 47: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 49/70 [01:32<00:36,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 48: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 50/70 [01:34<00:35,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 49: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 51/70 [01:36<00:33,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 50: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 52/70 [01:38<00:30,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 51: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 53/70 [01:39<00:30,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 52: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 54/70 [01:42<00:30,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 53: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 55/70 [01:44<00:29,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 54: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 56/70 [01:45<00:25,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 55: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 57/70 [01:47<00:23,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 56: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 58/70 [01:49<00:20,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 57: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 59/70 [01:50<00:18,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 58: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 60/70 [01:52<00:17,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 59: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 61/70 [01:54<00:16,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 60: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 62/70 [01:56<00:15,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 61: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 63/70 [01:58<00:12,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 62: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 64/70 [01:59<00:10,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 63: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 65/70 [02:01<00:08,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 64: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 66/70 [02:03<00:06,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 65: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 67/70 [02:04<00:05,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 66: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 68/70 [02:06<00:03,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 67: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 69/70 [02:08<00:01,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 68: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:10<00:00,  1.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 69: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:09<00:00,  1.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:16<00:00,  1.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:49<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 of 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 1/70 [00:02<02:30,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 0: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/70 [00:03<02:08,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 1: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/70 [00:06<02:14,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 2: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/70 [00:08<02:17,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 3: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/70 [00:10<02:21,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 4: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 6/70 [00:12<02:14,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 5: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/70 [00:14<02:03,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 6: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 8/70 [00:15<01:57,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 7: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/70 [00:17<01:52,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 8: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 10/70 [00:22<02:36,  2.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 9: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/70 [00:23<02:17,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 10: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 12/70 [00:25<02:03,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 11: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 13/70 [00:27<01:53,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 12: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 14/70 [00:28<01:46,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 13: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 15/70 [00:30<01:46,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 14: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 16/70 [00:32<01:44,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 15: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 17/70 [00:35<01:49,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 16: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 18/70 [00:36<01:42,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 17: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 19/70 [00:38<01:37,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 18: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 20/70 [00:40<01:37,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 19: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 21/70 [00:42<01:31,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 20: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 22/70 [00:43<01:26,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 21: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 23/70 [00:45<01:24,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 22: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 24/70 [00:48<01:30,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 23: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 25/70 [00:50<01:32,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 24: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 26/70 [00:52<01:25,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 25: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 27/70 [00:53<01:20,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 26: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 28/70 [00:55<01:16,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 27: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 29/70 [00:57<01:13,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 28: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 30/70 [00:59<01:14,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 29: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 31/70 [01:01<01:17,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 30: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 32/70 [01:03<01:15,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 31: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 33/70 [01:05<01:08,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 32: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 34/70 [01:06<01:05,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 33: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 35/70 [01:08<01:05,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 34: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 36/70 [01:10<01:01,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 35: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 37/70 [01:12<00:58,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 36: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 38/70 [01:14<00:58,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 37: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 39/70 [01:16<00:59,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 38: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 40/70 [01:18<00:57,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 39: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 41/70 [01:19<00:52,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 40: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 42/70 [01:21<00:49,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 41: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 43/70 [01:22<00:45,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 42: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 44/70 [01:24<00:43,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 43: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 45/70 [01:26<00:44,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 44: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 46/70 [01:28<00:44,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 45: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 47/70 [01:30<00:43,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 46: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 48/70 [01:32<00:39,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 47: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 49/70 [01:33<00:36,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 48: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 50/70 [01:35<00:36,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 49: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 51/70 [01:37<00:33,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 50: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 52/70 [01:38<00:31,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 51: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 53/70 [01:40<00:30,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 52: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 54/70 [01:43<00:30,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 53: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 55/70 [01:45<00:28,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 54: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 56/70 [01:46<00:25,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 55: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 57/70 [01:48<00:22,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 56: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 58/70 [01:49<00:20,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 57: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 59/70 [01:51<00:18,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 58: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 60/70 [01:53<00:17,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 59: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 61/70 [01:55<00:17,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 60: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 62/70 [01:57<00:15,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 61: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 63/70 [01:59<00:12,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 62: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 64/70 [02:00<00:10,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 63: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 65/70 [02:02<00:09,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 64: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 66/70 [02:04<00:06,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 65: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 67/70 [02:06<00:05,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 66: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 68/70 [02:08<00:03,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 67: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 69/70 [02:10<00:01,  1.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 68: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:12<00:00,  1.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 69: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:11<00:00,  1.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:20<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:46<00:00,  1.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 of 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 1/70 [00:01<02:16,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 0: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/70 [00:04<02:21,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 1: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/70 [00:06<02:13,  1.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 2: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/70 [00:07<02:00,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 3: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/70 [00:09<02:11,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 4: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 6/70 [00:11<01:59,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 5: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/70 [00:13<01:52,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 6: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 8/70 [00:14<01:47,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 7: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/70 [00:16<01:51,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 8: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 10/70 [00:20<02:18,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 9: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/70 [00:21<02:03,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 10: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 12/70 [00:23<01:51,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 11: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 13/70 [00:24<01:43,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 12: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 14/70 [00:26<01:37,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 13: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 15/70 [00:28<01:38,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 14: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 16/70 [00:30<01:38,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 15: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 17/70 [00:32<01:43,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 16: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 18/70 [00:34<01:37,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 17: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 19/70 [00:35<01:31,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 18: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 20/70 [00:37<01:32,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 19: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 21/70 [00:39<01:27,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 20: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 22/70 [00:41<01:22,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 21: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 23/70 [00:42<01:19,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 22: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 24/70 [00:44<01:24,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 23: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 25/70 [00:47<01:33,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 24: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 26/70 [00:49<01:25,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 25: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 27/70 [00:50<01:19,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 26: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 28/70 [00:52<01:14,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 27: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 29/70 [00:53<01:10,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 28: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 30/70 [00:55<01:11,  1.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 29: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 31/70 [00:57<01:12,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 30: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 32/70 [00:59<01:13,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 31: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 33/70 [01:01<01:07,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 32: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 34/70 [01:03<01:03,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 33: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 35/70 [01:05<01:03,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 34: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 36/70 [01:06<00:59,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 35: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 37/70 [01:08<00:56,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 36: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 38/70 [01:10<00:55,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 37: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 39/70 [01:12<00:58,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 38: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 40/70 [01:14<00:59,  1.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 39: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 41/70 [01:16<00:54,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 40: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 42/70 [01:17<00:51,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 41: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 43/70 [01:19<00:47,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 42: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 44/70 [01:21<00:44,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 43: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 45/70 [01:23<00:44,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 44: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 46/70 [01:25<00:44,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 45: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 47/70 [01:27<00:44,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 46: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 48/70 [01:28<00:40,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 47: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 49/70 [01:30<00:37,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 48: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 50/70 [01:32<00:36,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 49: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 51/70 [01:34<00:33,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 50: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 52/70 [01:35<00:31,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 51: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 53/70 [01:37<00:29,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 52: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 54/70 [01:39<00:30,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 53: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 55/70 [01:41<00:29,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 54: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 56/70 [01:43<00:26,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 55: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 57/70 [01:45<00:23,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 56: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 58/70 [01:46<00:20,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 57: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 59/70 [01:48<00:19,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 58: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 60/70 [01:50<00:18,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 59: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 61/70 [01:52<00:17,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 60: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 62/70 [01:54<00:15,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 61: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 63/70 [01:56<00:12,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 62: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 64/70 [01:57<00:10,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 63: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 65/70 [01:59<00:09,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 64: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 66/70 [02:01<00:07,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 65: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 67/70 [02:03<00:05,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 66: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 68/70 [02:05<00:03,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 67: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 69/70 [02:07<00:02,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 68: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [02:09<00:00,  1.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 69: video [(1, 3, 8, 244, 244), (1, 3, 32, 244, 244)], label torch.Size([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 12/70 [00:22<01:50,  1.90s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-80-1914182422.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_log_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-73-3998107683.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(in_model, in_optimizer, in_dataloaders, in_model_save_dir, in_log_dir, in_device)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nBatch {i}: video {vid_shapes}, label {batch['label'].shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0min_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0min_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-19-146616823.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;31m# carry out transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0msample_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Close the loaded video if last clip and reset parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-22-3202939552.py\u001b[0m in \u001b[0;36mtransform_fn\u001b[0;34m(single_input)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Normalize the video; [0, 255] --> [0, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train\n",
        "train(current_model, current_optimizer, current_dataloaders, model_save_dir, model_log_dir, current_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eCpNUhONbdn"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVUwQuj8oBI8"
      },
      "source": [
        "## Create Test Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsqrTqPDoDEN"
      },
      "outputs": [],
      "source": [
        "# create dataloaders\n",
        "test_dataloader = create_dataloader(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCjJZ7gCqFeP"
      },
      "source": [
        "## Loading Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebB40e82mMXX"
      },
      "outputs": [],
      "source": [
        "evaluation_target = 'test'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "eoPWYk4HxTZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVU9dWJXkDgI",
        "outputId": "1b686dd6-f2dc-4792-a027-60ea2d710073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (blocks): ModuleList(\n",
              "    (0): MultiPathWayWithFuse(\n",
              "      (multipathway_blocks): ModuleList(\n",
              "        (0): ResNetBasicStem(\n",
              "          (conv): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
              "          (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU()\n",
              "          (pool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
              "        )\n",
              "        (1): ResNetBasicStem(\n",
              "          (conv): Conv3d(3, 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
              "          (norm): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activation): ReLU()\n",
              "          (pool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
              "        )\n",
              "      )\n",
              "      (multipathway_fusion): FuseFastToSlow(\n",
              "        (conv_fast_to_slow): Conv3d(8, 16, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
              "        (norm): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (1): MultiPathWayWithFuse(\n",
              "      (multipathway_blocks): ModuleList(\n",
              "        (0): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(1), np.int64(1)), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(80, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-2): 2 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(1), np.int64(1)), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(8, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-2): 2 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(32, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multipathway_fusion): FuseFastToSlow(\n",
              "        (conv_fast_to_slow): Conv3d(32, 64, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
              "        (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (2): MultiPathWayWithFuse(\n",
              "      (multipathway_blocks): ModuleList(\n",
              "        (0): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(2), np.int64(2)), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-3): 3 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(2), np.int64(2)), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(32, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-3): 3 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multipathway_fusion): FuseFastToSlow(\n",
              "        (conv_fast_to_slow): Conv3d(64, 128, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
              "        (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (3): MultiPathWayWithFuse(\n",
              "      (multipathway_blocks): ModuleList(\n",
              "        (0): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(2), np.int64(2)), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(640, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-5): 5 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(2), np.int64(2)), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(64, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-5): 5 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multipathway_fusion): FuseFastToSlow(\n",
              "        (conv_fast_to_slow): Conv3d(128, 256, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
              "        (norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (4): MultiPathWayWithFuse(\n",
              "      (multipathway_blocks): ModuleList(\n",
              "        (0): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(2), np.int64(2)), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(1280, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-2): 2 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResStage(\n",
              "          (res_blocks): ModuleList(\n",
              "            (0): ResBlock(\n",
              "              (branch1_conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(2), np.int64(2)), bias=False)\n",
              "              (branch1_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(128, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1-2): 2 x ResBlock(\n",
              "              (branch2): BottleneckBlock(\n",
              "                (conv_a): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_a): ReLU()\n",
              "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                (act_b): ReLU()\n",
              "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (multipathway_fusion): Identity()\n",
              "    )\n",
              "    (5): PoolConcatPathway(\n",
              "      (pool): ModuleList(\n",
              "        (0): AvgPool3d(kernel_size=(8, 7, 7), stride=(1, 1, 1), padding=(0, 0, 0))\n",
              "        (1): AvgPool3d(kernel_size=(32, 7, 7), stride=(1, 1, 1), padding=(0, 0, 0))\n",
              "      )\n",
              "    )\n",
              "    (6): ResNetBasicHead(\n",
              "      (dropout): Dropout(p=0.5, inplace=False)\n",
              "      (proj): Linear(in_features=2304, out_features=2, bias=True)\n",
              "      (output_pool): AdaptiveAvgPool3d(output_size=1)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "current_model, current_device = create_model(N_CLASSES, model_type=MODEL, freeze_body=FREEZE_BODY)\n",
        "model_weights = torch.load(\"/content/MyDrive/MyDrive/autosynthda/action-recognition/checkpoint/06-22-2025-12-52-04/saved_models/best_model_acc.pth\")\n",
        "current_model.load_state_dict(model_weights)\n",
        "current_model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4XVvSjroIC3"
      },
      "source": [
        "## Obtain Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3Dt0YkrkHlq",
        "outputId": "13f0ec43-6f4c-485c-9ad3-d1db39f75c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining predictions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:44<00:00,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['label', 'prediction', 'result']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# obtain model predictions\n",
        "df_model_preds = obtain_model_predictions(current_model, test_dataloader, current_device)\n",
        "# save\n",
        "df_model_preds.to_csv(os.path.join(model_evaluation_dir, \"predictions_{}.csv\").format(evaluation_target),index=0)\n",
        "\n",
        "df_model_preds\n",
        "print(df_model_preds.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Point to the CSV you saved from the best-accuracy checkpoint\n",
        "csv_path = \"/content/MyDrive/MyDrive/autosynthda/action-recognition/checkpoint/06-22-2025-12-52-04/model_evaluation/predictions_test.csv\"\n",
        "# e.g. \"/content/drive/.../predictions_test_acc.csv\"\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# accuracy  = fraction of rows where prediction matches the ground-truth label\n",
        "accuracy = (df[\"label\"] == df[\"prediction\"]).mean()\n",
        "\n",
        "# 0-1 loss  = 1 − accuracy\n",
        "zero_one_loss = 1 - accuracy\n",
        "\n",
        "print(f\"Accuracy       : {accuracy:.4f}\")\n",
        "print(f\"misclassifying loss: {zero_one_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTvFoTS_3pkD",
        "outputId": "79c97ad7-58e9-44d3-ba7a-d5e1e42aedc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy       : 0.5000\n",
            "misclassifying loss: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQzFXR7CoMio"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "1BiSKYwKkH5k",
        "outputId": "3bbf1d00-e521-4fdd-9e97-f3f9c56ac4c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     label   action total correct incorrect per_correct per_incorrect\n",
              "0        0      adl    12       0        12       0.0 %       100.0 %\n",
              "1        1     fall    12      12         0     100.0 %         0.0 %\n",
              "2  Overall  Overall    24      12        12      50.0 %        50.0 %"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4cef1c6-e70d-42c2-9b71-17f419332ce5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>action</th>\n",
              "      <th>total</th>\n",
              "      <th>correct</th>\n",
              "      <th>incorrect</th>\n",
              "      <th>per_correct</th>\n",
              "      <th>per_incorrect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>adl</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0.0 %</td>\n",
              "      <td>100.0 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>fall</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>100.0 %</td>\n",
              "      <td>0.0 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Overall</td>\n",
              "      <td>Overall</td>\n",
              "      <td>24</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>50.0 %</td>\n",
              "      <td>50.0 %</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4cef1c6-e70d-42c2-9b71-17f419332ce5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4cef1c6-e70d-42c2-9b71-17f419332ce5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4cef1c6-e70d-42c2-9b71-17f419332ce5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8f44db53-994a-484b-9fe1-2459fe8e9cad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f44db53-994a-484b-9fe1-2459fe8e9cad')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8f44db53-994a-484b-9fe1-2459fe8e9cad button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c2a05094-7a31-4699-bd5c-b2e2a6490009\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_class_accuracy')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c2a05094-7a31-4699-bd5c-b2e2a6490009 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_class_accuracy');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_class_accuracy",
              "summary": "{\n  \"name\": \"df_class_accuracy\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          \"Overall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"action\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"adl\",\n          \"fall\",\n          \"Overall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 12,\n        \"max\": 24,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          24,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          12,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incorrect\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"per_correct\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"0.0 %\",\n          \"100.0 %\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"per_incorrect\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"100.0 %\",\n          \"0.0 %\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# calculate per class accuracy\n",
        "df_class_accuracy = per_class_accuracy(df_model_preds,'label')\n",
        "\n",
        "# save\n",
        "df_class_accuracy.to_csv(os.path.join(model_evaluation_dir, \"accuracy_{}.csv\").format(evaluation_target),index=0)\n",
        "\n",
        "df_class_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "Cq1FsxKwmVS_",
        "outputId": "6531e4ba-1d66-4ad4-eeb0-8292bbc38e03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-36-1374590303.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  out_df_confusion_data = pd.concat([out_df_confusion_data,df_dict],ignore_index=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "prediction    0      1\n",
              "label                 \n",
              "0           0.0  100.0\n",
              "1           0.0    0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16c5e72b-8e66-41b5-859b-c8fe19038498\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>prediction</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16c5e72b-8e66-41b5-859b-c8fe19038498')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16c5e72b-8e66-41b5-859b-c8fe19038498 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16c5e72b-8e66-41b5-859b-c8fe19038498');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fba92f25-6a8c-4e06-a613-2a7470a0a6f8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fba92f25-6a8c-4e06-a613-2a7470a0a6f8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fba92f25-6a8c-4e06-a613-2a7470a0a6f8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6ec1add8-fe4e-48aa-b503-532115c04ab7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_heatmap')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6ec1add8-fe4e-48aa-b503-532115c04ab7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_heatmap');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_heatmap",
              "summary": "{\n  \"name\": \"df_heatmap\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70.71067811865476,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# generate confusion matrix\n",
        "df_confusion_data = generate_confusion_data(df_model_preds,'label','prediction',remove_correct=True)\n",
        "df_heatmap = df_confusion_data.pivot(index='label',columns='prediction',values='percentage')\n",
        "\n",
        "# save\n",
        "df_heatmap.to_csv(os.path.join(model_evaluation_dir, \"confusion_{}.csv\").format(evaluation_target),index=0)\n",
        "\n",
        "df_heatmap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output to .txt file for export to main AutoSynthDa pipeline"
      ],
      "metadata": {
        "id": "HS6mYLz69IA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------\n",
        "# 1) user-defined “weight” to embed in the file names\n",
        "# --------------------------------------------------------------------\n",
        "weight_val = 0.4                       # <= set this to 0.2, 0.3, … as needed\n",
        "print(\"Columns in df_class_accuracy:\", df_class_accuracy.columns.tolist())\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 2) where to save them\n",
        "# --------------------------------------------------------------------\n",
        "txt_dir = '/content/MyDrive/MyDrive/autosynthda/action-recognition/results/'        # or any other folder you prefer\n",
        "#txt_dir = \"/content/MyDrive/MyDrive/autosynthda/action-recognition/results\"\n",
        "\n",
        "timestamp          = datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\")\n",
        "current_output_dir = os.path.join(txt_dir, timestamp)\n",
        "\n",
        "os.makedirs(current_output_dir, exist_ok=True)   # <-- THIS was missing\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 2.  File paths\n",
        "# --------------------------------------------------------------------\n",
        "acc_txt_path  = os.path.join(current_output_dir, f\"acc_{weight_val}.txt\")\n",
        "loss_txt_path = os.path.join(current_output_dir, f\"loss_{weight_val}.txt\")\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 3.  Write per-class accuracies\n",
        "# --------------------------------------------------------------------\n",
        "with open(acc_txt_path, \"w\") as f:\n",
        "    for _, row in df_class_accuracy.iterrows():\n",
        "        cls = row[\"action\"]\n",
        "\n",
        "        acc_str = str(row[\"per_correct\"]).strip()\n",
        "        acc_val = (float(acc_str.rstrip(\"%\").strip()) / 100.0\n",
        "                   if acc_str.endswith(\"%\") else float(acc_str))\n",
        "\n",
        "        f.write(f\"acc_{weight_val}_{cls} = {acc_val:.4f}\\n\")\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# 4.  Write overall loss\n",
        "# --------------------------------------------------------------------\n",
        "with open(loss_txt_path, \"w\") as f:\n",
        "    f.write(f\"loss_weight_{weight_val} = {zero_one_loss:.4f}\\n\")\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\" •\", acc_txt_path)\n",
        "print(\" •\", loss_txt_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-5vD5vz9HrN",
        "outputId": "ec61b255-ef13-4904-a662-45cd2658bc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in df_class_accuracy: ['label', 'action', 'total', 'correct', 'incorrect', 'per_correct', 'per_incorrect']\n",
            "Saved:\n",
            " • /content/MyDrive/MyDrive/autosynthda/action-recognition/results/06-22-2025-14-15-28/acc_0.4.txt\n",
            " • /content/MyDrive/MyDrive/autosynthda/action-recognition/results/06-22-2025-14-15-28/loss_0.4.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "smQnC3aqmU_g",
        "outputId": "5f0ebd5a-ba08-4937-98d6-c22d24bf3735"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1600x900 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# display\n",
        "plt.figure(figsize=(16,9))\n",
        "sns.heatmap(df_heatmap,annot=True,fmt='g',cmap='inferno',vmax=100,linewidths=4)\n",
        "plt.title('Incorrect Percentage (%)')\n",
        "plt.savefig(os.path.join(model_evaluation_dir, \"confusion_matrix_{}.jpg\").format(evaluation_target))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ej_IyrLm6xf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hPwjpfzCNXWx",
        "okPBr84WNWW2",
        "7RfaH8aLOO2c",
        "UClQXF5TSzKb",
        "vdAxqNeybKNg",
        "wBuEA_LwbNiP",
        "gCr7VKsKbFxr",
        "5uJczSjQc6Zz",
        "lZ_PCjpU0i3s",
        "YspkQdR7MmEf",
        "9eayGf5X0qZO",
        "ysRr_Xm5VFtN",
        "i4tqGLLeYfoX",
        "uOxMqMfIf3JJ",
        "OQBnBd1on7eo"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}